{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df21c37f",
   "metadata": {},
   "source": [
    "# CSE5ML: Machine Learning\n",
    "# Assessment 2: Image Classification with Neural Networks\n",
    "\n",
    "## Completion Requirements\n",
    "\n",
    "- **Working code and written report**\n",
    "- **Due date:** 11.59 pm (AEST), Sunday 14 September 2025 (Week 7)\n",
    "- **Weighting:** 30%\n",
    "- **Length:** Working code and 1000-word report (+/‚Äì 10%)\n",
    "- **SILOs:** Implement a neural network with different learning algorithms for time-series forecasting with real-world data from industry (SILO 4).\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this assessment is to develop hands-on experience with neural networks for image classification ‚Äì a key application of machine learning used across industries such as health care, autonomous systems and digital security to interpret and act on visual data.\n",
    "\n",
    "## Task Details\n",
    "\n",
    "This assessment aims to consolidate your knowledge and practical skills to build neural networks (NNs) for supervised learning. The task is formulated as a multi-class classification problem for handwritten images, and the goal is to model the relationship between the images‚Äô content, network structure and labels. You need to provide:\n",
    "\n",
    "- **Working code** (part 1)\n",
    "- **A written report** of 1000 words on the method and results (part 2).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "The MNIST database is a dataset with handwritten digits (from 0 to 9). The digits have been size-normalised and centred in a fixed-size image (28 √ó 28 pixels) with values from 0 to 1. You can use the following code with TensorFlow in Python to download the data.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We will call the images ùë• and the labels ùë¶. Both the training set and test set contain ùë• and ùë¶.\n",
    "Each image is 28 pixels by 28 pixels.\n",
    "As mentioned, the corresponding labels in the MNIST are numbers between 0 and 9, describing which digit a given image represents. In this assessment, we regard the labels as one-hot vectors; that is, 0 in most dimensions, and 1 in a single dimension. In this case, the ùëõ-th digit will be represented as a vector, which is 1 in the ùëõ dimensions. For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n",
    "The assessment aims to build NNs for classifying handwritten digits in the MNIST database, train it on the training set and test it on the test set. Since the main object of this assessment is for you to understand the relationship between input, model and output, you are not expected to achieve very high accuracy in model performance; instead, for each task, you should be able to identify how you can improve model performance with the change of network structure.\n",
    "\n",
    "There are two parts to this assessment:\n",
    "\n",
    "### Part 1\n",
    "Part 1 is comprised of three main tasks:\n",
    "\n",
    "**Task 1**\n",
    "\n",
    "Build a neural network without convolutional layers to do the classification task (hint: you will need the use of dense layers). Then you can change the model structure (i.e. number of dense layers, number of neurons in dense layers or activation functions) to be able to improve network performance.\n",
    "\n",
    "**Task 2**\n",
    "\n",
    "Build a neural network with the use of convolutional layers (you can decide other layer types you want to include in your network). Then you can change the number of convolutional layers and the number of filters or activation functions in the convolutional layers to be able to improve network performance.\n",
    "\n",
    "**Task 3**\n",
    "\n",
    "Change the type of optimiser or learning rate that you applied in the previous tasks and see how these changes can influence model performance. (You can keep the final network structure you applied in task 2 and try at least one different optimiser setting.)\n",
    "Please read the following comments and requirements very carefully before starting the assessment:\n",
    "1.\tThe assessment is based on the content of labs and Weeks 1‚Äì3.\n",
    "2.\tIn Week 1 we talked about the use of training set, validation set and test set in machine learning. In this assessment, you are asked to train the NN on the training set and test the NN on the test set, without any given validation set. (If you want to monitor the training process, you can also try what we did in Week 3: you can consider the validation set is the same as the test set in this assessment.)\n",
    "3.\tIn the assessment, the performance of an NN is measured by its prediction accuracy in classifying images from the test set (i.e. number of the correctly predicted images/number of the images in the test set).\n",
    "4.\tSince the MNIST dataset is a black-and-white image dataset, the shape of dataset is (dataset_length, 28,28). But to fit it into a conv2d layer, we need to make the input shape comply with its required format: (batch_size, image_width, image_depth, image_channels). Although batch_size can be decided later when you train it, you will still need to tell the number of image channels here. You can consider reshaping the dataset into (dataset_length, 28,28,1) or add one more dimension at the end with np.newaxis.\n",
    "5.\tYou are expected to show at least two models in for tasks 1 and 2: one for the model you start with, and another model is the model that you identified to have better accuracy. For task 3, you need to show what optimiser and/or learning rate you applied.\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Your report must at least contain the following content:\n",
    "1.\tYour name and student number.\n",
    "2.\tArchitectures of the NNs, with figures for tasks 1 and 2.\n",
    "3.\tDescription on the optimiser and learning rate you applied in the final model of task 2 and the optimiser or change of learning rate you used in task 3.\n",
    "4.\tExperiments and performances, with parameter setting.\n",
    "5.\tDiscussion on the improvement/deterioration of the NN‚Äôs performance after changing the architecture and parameter setting for each task and findings of comparing the results from all three tasks.\n",
    "6.\tThe ranking of all NNs‚Äô performances from all the three tasks.\n",
    "\n",
    "### Assessment criteria\n",
    "\n",
    "This assessment will measure your ability to:\n",
    "\n",
    "**Part 1:**\n",
    "\n",
    "‚Ä¢\tdescribe the two models, experiment settings and compare the results for task 1 (25%)\n",
    "‚Ä¢\tdescribe the two models, experiment settings and compare the results for task 2 (25%)\n",
    "‚Ä¢\tdescribe the two optimisers or learning rates, experiment settings and compare the results for task 3 (35%)\n",
    "\n",
    "**Part 2:**\n",
    "\n",
    "‚Ä¢\tdemonstrate correct code quality (10%)\n",
    "‚Ä¢\tresearch extensively and demonstrate depth of thinking; produce a well-structured report (5%).\n",
    "Refer to the marking guide for marking and feedback information.\n",
    "\n",
    "### Submission details\n",
    "\n",
    "The submitted assessment consists of (1) a report (in PDF format) of no less than 1000 words and (2) all codes for modelling, training and testing the NN with TensorFlow in Python (you can choose to have one code file including all your codes, or you can have one code file for each task separately).\n",
    "**If you use ChatGPT or other generative AI tools, you must cite them and clearly indicate your original contributions.**\n",
    "\n",
    "In keeping with La Trobe University policy, all assignments are to be submitted in Moodle via Turnitin.\n",
    "To be accepted, your assessment submission **must** generate a similarity score (you are responsible for checking this). Submitting in Word or PDF format is the best way to do this. If your submission does not generate a similarity score, it cannot be checked for plagiarism and therefore **will not be marked.**\n",
    "\n",
    "Last modified: Tuesday, 12 August 2025, 8:58 PM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a43b04",
   "metadata": {},
   "source": [
    "# Part 1, task 1 & 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85a5a6",
   "metadata": {},
   "source": [
    "### Import relevant dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the MNIST dataset from Keras, a classic collection of 70,000 grayscale images of handwritten digits (0-9).\n",
    "from keras.datasets import mnist \n",
    "\n",
    "# Imports TensorFlow, the core open-source library from Google for building and training machine learning models. We use the alias 'tf' by convention.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Imports the Adam optimiser. An optimiser is an algorithm that adjusts the model's internal parameters (weights) to minimise the error, and Adam is a popular, efficient choice.\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Imports specific performance metrics. Metrics are used to evaluate how well the model is performing.\n",
    "# Precision: Measures the accuracy of positive predictions.\n",
    "# Recall: Measures the model's ability to find all the actual positive instances.\n",
    "# Accuracy: Measures the overall fraction of correct predictions.\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "\n",
    "# Imports the History callback object. A 'callback' is a function that can be executed at different stages of training. The History object automatically records the metrics and loss values from each epoch.\n",
    "from tensorflow.python.keras.callbacks import History\n",
    "\n",
    "# Imports the ModelCheckpoint callback. This callback saves the model to a file during training, typically only when its performance on a validation metric improves.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Imports the Pandas library, a powerful tool for data manipulation and analysis. It's mainly used for working with structured data in tables called DataFrames. 'pd' is the standard alias.\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the Sequential model type from Keras. This is the simplest way to build a model, by creating a linear stack of layers.\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Imports different types of layers, which are the fundamental building blocks of a neural network.\n",
    "# Dense: A standard, fully-connected layer where each neuron is connected to every neuron in the previous layer.\n",
    "# Input: A special layer used to define the shape and data type of the model's input.\n",
    "# Flatten: A layer that transforms a multi-dimensional input (like a 2D image) into a one-dimensional vector.\n",
    "# Normalization: A preprocessing layer that scales input data to a standard range (e.g., mean of 0, standard deviation of 1), which helps the model train faster. \n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Normalization, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Imports a utility function from scikit-learn, a popular library for traditional machine learning. train_test_split is used to split a single dataset into separate training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports the pyplot interface from Matplotlib, which is the most widely used library for creating plots and visualisations in Python. 'plt' is the standard alias.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports the NumPy library, which is the foundation for numerical computing in Python. It provides support for large, multi-dimensional arrays and a wide range of mathematical functions. 'np' is the standard alias.\n",
    "import numpy as np\n",
    "\n",
    "# Imports a data scaling tool from scikit-learn. MinMaxScaler scales all data features to a specific range, usually 0 to 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Imports tools for 'type hinting' from Python's typing module. Type hints make code more readable and can be used by external tools to check for errors.\n",
    "# Tuple: Used to hint that a variable or function return is a tuple (an ordered, immutable collection of elements).\n",
    "from typing import Tuple\n",
    "\n",
    "# Imports a specific type hint from NumPy's typing module.\n",
    "# NDArray: Used to hint that a variable is a NumPy n-dimensional array, which is more descriptive than a generic type.\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Imports the 'os' module. This library provides a way for Python to interact with the computer's underlying operating system.\n",
    "# We use it for tasks like reading file names from a folder (os.listdir()) and constructing file paths that work correctly on any system, like Windows, Mac, or Linux (os.path.join()).\n",
    "import os \n",
    "\n",
    "# Imports the 're' module, which stands for Regular Expression. This is Python's library for advanced pattern matching in strings.\n",
    "# We use it to find and extract specific pieces of text from a string, like pulling the accuracy score out of a complex filename (e.g., finding '0.9935' in 'model_acc-0.9935.keras').\n",
    "import re\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ce86f",
   "metadata": {},
   "source": [
    "### Define the training set features (X_train) and target variable (Y_train) as well as the test set features (X_test_) and target variable (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b32fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset, which is a large database of handwritten digits.\n",
    "# The function returns two tuples: one for training data and one for testing data.\n",
    "# Recalling, a Tuple is a collection of objects that are ordered and immutable.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# First we convert the data to float32, which helps with numerical stability. A float32 provides sufficient precision, while also being memory efficient.\n",
    "# Most modern CPU's and GPU's are optimized for float32 operations, making computations faster.\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# Then we convert the training data to have a channel dimension, which is required for CNNs.\n",
    "X_train = X_train[..., tf.newaxis] # Add the channel dimension\n",
    "X_test = X_test[..., tf.newaxis] # Add the channel dimension\n",
    "print(f\"New shape for X_train for CNN's: {X_train.shape}\")\n",
    "print(f\"New shape for X_test for CNN's: {X_test.shape}\")\n",
    "\n",
    "# Declare the types of the loaded data for clarity.\n",
    "X_train: NDArray[np.float32]\n",
    "Y_train: NDArray[np.uint8]\n",
    "X_test: NDArray[np.float32]\n",
    "Y_test: NDArray[np.uint8]\n",
    "\n",
    "# We set the line width to a large value to avoid line breaks when printing the array.\n",
    "with np.printoptions(linewidth=10000):\n",
    "    # Print the shapes of the datasets to understand their dimensions.\n",
    "    print(\"Shape of X_train:\\t\", X_train.shape)\n",
    "    print(\"Shape of X_test:\\t\", X_test.shape)\n",
    "    print(\"Shape of Y_train:\\t\", Y_train.shape)\n",
    "    print(\"Shape of Y_test:\\t\", Y_test.shape)\n",
    "    print(f\"X_train data type: {X_train.dtype}\")\n",
    "    print(f\"X_test data type: {X_test.dtype}\")\n",
    "    print(f\"Y_train data type: {Y_train.dtype}\")\n",
    "    print(f\"Y_test data type: {Y_test.dtype}\")\n",
    "\n",
    "    # Inspect a single data sample to see what it looks like.\n",
    "    n: int = 5678\n",
    "    print(f\"\\nX_train data {n}-th element (a 28x28 pixel image):\\n\", np.squeeze(X_train[n]))\n",
    "    print(\"\\nAnd its corresponding label:\\t\", Y_train[n])\n",
    "\n",
    "    # TODO: For using this data in a neural network,\n",
    "    # Tensorflow/Keras expects the input data to be in a 1D or 2D array format where each row represents a single sample and each column represents a feature. The general format for the input shape is: (batch_size, feature_1, feature_2, ...)\n",
    "    # However, we can use the tf.keras.layers.Flatten layer as the first layer in our sequential model.\n",
    "    # This layer automatically flattens the input shape without the need for manual reshaping of our data.\n",
    "    # For a Dense (fully connected) network: We must flatten each 28x28 image into a single 1D array of 784 pixels. The input shape for the first layer of our model would then be (None, 784), where None represents a variable batch size.\n",
    "    # For a Convolutional Neural Network (CNN): We must add a channel dimension. Since the images are grayscale, there is only one channel. We would reshape the data to (number_of_images, 28, 28, 1). The input shape for the first layer (typically a Conv2D layer) would be (28, 28, 1). The batch size is handled automatically by Keras.\n",
    "    # Scaling can also be performd in the model using a tf.keras.layers.Rescaling or keras.layers.Normalization layer as the first layer in our sequential model.\n",
    "    # The advantage of using these layers is that they integrate seamlessly into the model architecture, ensuring that the data is preprocessed consistently during both training and inference.\n",
    "    # This approach also simplifies the code by reducing the need for separate preprocessing steps outside the model definition.\n",
    "    # And, it ensures that inference data is processed in the same way as training data, which is crucial for maintaining model performance.\n",
    "\n",
    "    # Analyze the distribution of the digits in the training set.\n",
    "    # `np.unique` finds the unique digit labels and `return_counts=True` counts their occurrences.\n",
    "    dataset_distribution: Tuple[np.ndarray, np.ndarray] = np.unique(Y_train, return_counts=True)\n",
    "    digits: np.ndarray = dataset_distribution[0]\n",
    "    counts: np.ndarray = dataset_distribution[1]\n",
    "    \n",
    "    print(\"\\n--- Dataset Distribution ---\")\n",
    "    print(\"Digits:\\t\\t\\t\", digits)\n",
    "    print(\"Count per digit:\\t\", counts)\n",
    "    \n",
    "    # Calculate basic statistics on the distribution.\n",
    "    avg: float = np.mean(counts)\n",
    "    print(f\"Average sample size:\\t {avg:.2f}\")\n",
    "    \n",
    "    max_count: np.int64 = np.max(counts)\n",
    "    min_count: np.int64 = np.min(counts)\n",
    "    print(f\"Maximum sample size:\\t {max_count}\")\n",
    "    print(f\"Minimum sample size:\\t {min_count}\")\n",
    "\n",
    "# Create a bar chart from the counts and digits to visualize the distribution.\n",
    "plt.bar(digits, counts, color='blue', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for clarity.\n",
    "plt.title('Count of Each Digit in Training Set')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Set x-ticks to be at the center of each bar and label them with the digit.\n",
    "plt.xticks(digits)\n",
    "\n",
    "# Add a grid for better readability.\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d4acf",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "The content and size of the training and testing datasets align with the description on the Kaggle MNIST dataset page, Hojjat, F. (2017). MNIST: The Most Famous Dataset in the World. Kaggle. Retrieved August 28, 2025, from https://www.kaggle.com/datasets/hojjatk/mnist-dataset. The plot of digit distribution shows a fairly homogeneous representation across all classes (digits 0 through 9). While the digit '1' is slightly oversampled and the digit '5' is slightly undersampled, the class imbalance is not significant enough to warrant further action for this assessment.\n",
    "\n",
    "In a scenario where the distribution were to be significantly imbalanced and we needed to make it more homogeneous, we would use a technique called **resampling**. Resampling involves adjusting the distribution of the training data to be more balanced. There are two primary types:\n",
    "\n",
    "- **Oversampling** involves duplicating samples from the underrepresented classes to increase their frequency.\n",
    "\n",
    "- **Undersampling** involves removing samples from the overrepresented classes to reduce their frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5568184",
   "metadata": {},
   "source": [
    "## Part 1, Task 1: Creating a simple Multilayer Perceptron (MLP) neural network\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set Seeds for Reproducibility ---\n",
    "\n",
    "# This sets the global random seed for all TensorFlow operations.\n",
    "# It ensures that things like model weight initialisation are the same every time.\n",
    "# `tf.random.set_seed()` is the modern way to do this in TensorFlow 2.\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# This sets the random seed for all NumPy operations.\n",
    "# This is important if we are creating our data using NumPy or using any\n",
    "# NumPy functions that involve randomness.\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44356e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NO LONGER REQUIRED, BUT LEFT HERE FOR FUTURE PROJECTS WHERE A SINGLE MODEL IS ENOUGH, AND TO DEMONSTRATE THE BASIC CODE BASE.\n",
    "# THE CELLS BELOW SPLIT UP THIS CODE IN A MODEL CREATION PART, A RUN EXPERIMENT PART, AND HYPERPARAMETER TUNING PART, ALLOWING FOR MUCH MORE FLEXIBILITY. \n",
    "\n",
    "# # --- 1. Define the MLP BASE Model Architecture ---\n",
    "# # We are building a Sequential model, which is a simple, linear stack of layers.\n",
    "# mnist_model_mlp: Sequential = Sequential([\n",
    "#     # This is our preprocessing layer for Z-score scaling (normalisation with mean 0 and std. dev 1).\n",
    "#     # It learns the mean and standard deviation from the training data and applies it.\n",
    "#     # The input_shape must match a single sample from our data, which is a 28x28 image.\n",
    "#     # We define the normalisation and flattening inside the model so that\n",
    "#     # they are applied consistently during both training and inference.\n",
    "#     Input(shape=(28, 28, 1)),\n",
    "#     Normalization(),\n",
    "\n",
    "#     # The Flatten layer converts the 2D image (28x28) into a 1D vector (784 elements).\n",
    "#     # This is a necessary step to feed the data into the Dense (fully-connected) layers.\n",
    "#     Flatten(),\n",
    "\n",
    "#     # These are our hidden layers. We use the 'relu' activation function to help\n",
    "#     # the model learn complex, non-linear patterns in the pixel data.\n",
    "#     Dense(units=128, activation='relu'),\n",
    "#     Dense(units=256, activation='relu'),\n",
    "#     Dense(units=64, activation='relu'),\n",
    "\n",
    "#     # This is our output layer. It must have 10 neurons (one for each digit 0-9).\n",
    "#     # The 'softmax' activation converts the output into a probability distribution,\n",
    "#     # showing the model's confidence for each digit.\n",
    "#     Dense(units=10, activation='softmax')\n",
    "# ], name=\"MLP_Base\")\n",
    "\n",
    "# # We can print a summary of the model's architecture to see the layers and parameter counts.\n",
    "# print(\"\\n--- Model Architecture ---\")\n",
    "# mnist_model_mlp.summary()\n",
    "\n",
    "# # for n in range(len(mnist_model_mlp.layers)):\n",
    "# #     print(f\"MNIST model layer[{n}: {mnist_model_mlp.layers[n]}]\")\n",
    "\n",
    "# # --- 2. Adapt the Normalisation Layer ---\n",
    "# # Before training, we must let the Normalization layer calculate the mean and\n",
    "# # variance of our training data. The .adapt() method does this for us.\n",
    "# print(\"Adapting the normalisation layer to the training data...\")\n",
    "# mnist_model_mlp.layers[0].adapt(X_train)\n",
    "# print(\"Adaptation complete.\")\n",
    "\n",
    "\n",
    "# # --- 3. Configure and Compile the Model ---\n",
    "# # We configure the optimiser and the list of metrics we want to track.\n",
    "# adam_optimizer: Adam = Adam(learning_rate=0.001)\n",
    "# metrics_list: list = ['accuracy'] #, Precision(), Recall()] Precision and Recall can be used for Binary Classification problems only.\n",
    "\n",
    "# # The compile step brings everything together and prepares the model for training.\n",
    "# mnist_model_mlp.compile(\n",
    "#     optimizer=adam_optimizer,\n",
    "#     loss='sparse_categorical_crossentropy', # Best for integer labels in multi-class classification, such as our MNIST labels (i.e. 0, 1, 2, ..., 9). Keras' sparse_categorical_crossentropy handles the one-hot encoding for us internally. \n",
    "#     metrics=metrics_list\n",
    "# ) # See Cholet Book, Section 8.1 and Deep Learning Goodfellow, section 5.5 and 6.2.2.2\n",
    "\n",
    "# # Define the filepath for the saved model.\n",
    "# # The placeholders {epoch:02d} and {val_accuracy:.4f} will be automatically filled in.\n",
    "# folder_name = 'MLP Models'\n",
    "# filepath = f'{folder_name}/best_{mnist_model_mlp.name}_epoch-{{epoch:02d}}_val_acc-{{val_accuracy:.4f}}.keras'\n",
    "\n",
    "# # Create a ModelCheckpoint callback so we can save the best model during training. Note: every epoch the model is evaluated\n",
    "# # on validation accuracy. If the validation accuracy improves, the model will be saved. If not, it will not be saved.\n",
    "# model_checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath=filepath,\n",
    "#     monitor='val_accuracy',      # Monitor the validation accuracy\n",
    "#     mode='max',                  # The direction of improvement (higher is better for accuracy)\n",
    "#     save_best_only=True,         # Only save the model if `val_accuracy` has improved\n",
    "#     verbose=1                    # Print a message when the model is saved\n",
    "# )\n",
    "\n",
    "# # --- 4. Train the Model ---\n",
    "# # This is where the learning happens. The .fit() method trains the model on our data, and returns a History object.\n",
    "# # The 'history' object will store the loss and metric values for each epoch.\n",
    "# history_mlp: History = mnist_model_mlp.fit(\n",
    "#     X_train,\n",
    "#     Y_train,\n",
    "#     epochs=5,\n",
    "#     validation_split=0.1, # We hold back 10% of the training data to validate performance.\n",
    "#     batch_size=64,\n",
    "#     verbose=1, # We set verbose=1 to see the training progress bar.\n",
    "#     callbacks=[model_checkpoint_callback], \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_creation_func, hyperparameters, parent_folder, X_train, Y_train) -> History:\n",
    "    \"\"\"\n",
    "    Runs a full training experiment for a given model architecture and hyperparameter set.\n",
    "    \"\"\"\n",
    "    # Create a fresh instance of the model for this experiment. We do this by calling the model creation function, which is\n",
    "    # passed as an argument to this function.\n",
    "    model = model_creation_func()\n",
    "    model.name = hyperparameters.get('model_name', 'unnamed_model')\n",
    "    \n",
    "    print(f\"\\n--- Starting Experiment: ---\")\n",
    "\n",
    "    # We can print a summary of the model's architecture to see the layers and parameter counts.\n",
    "    print(\"\\n--- Model Architecture ---\")\n",
    "    model.summary() # This includes the name of the model as well.\n",
    "\n",
    "    # And we can also print the hyperparameters of the model.\n",
    "    print(\"\\n--- Hyperparameters ---\")\n",
    "    for key, value in hyperparameters.items():\n",
    "        print(f\"{key:<20}: {value}\")\n",
    "\n",
    "    # --- Adapt the Normalisation Layer ---\n",
    "    print(\"\\nAdapting the normalisation layer...\")\n",
    "    model.layers[0].adapt(X_train)\n",
    "    print(\"Adaptation complete.\\n\")\n",
    "\n",
    "    # --- Configure the Optimiser ---\n",
    "    optimiser_name = hyperparameters.get('optimiser', 'adam').lower() # if not provided, default to Adam\n",
    "    learning_rate = hyperparameters.get('learning_rate', 0.001) # if not provided, default to 0.001\n",
    "\n",
    "    # The reason we use an optimiser Object, rather than a string name, is to allow for more complex configurations in the future.\n",
    "    # such as: learning rate schedules, gradient clipping, weight decay amongst others. \n",
    "    # This is not used in this workbook, but it makes the code more robust for future (personal) projects. \n",
    "    if optimiser_name == 'adam':\n",
    "        optimiser = Adam(learning_rate=learning_rate)\n",
    "    elif optimiser_name == 'sgd':\n",
    "        optimiser = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimiser = optimiser_name\n",
    "\n",
    "    # --- Configure the ModelCheckpoint Callback ---\n",
    "    model_specific_folder = os.path.join(parent_folder, model.name)\n",
    "    filepath = os.path.join(model_specific_folder, 'best_model_epoch-{epoch:02d}_val_acc-{val_accuracy:.4f}.keras')\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # --- Compile the Model ---\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss=hyperparameters.get('loss_function', 'sparse_categorical_crossentropy'),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # --- Train the Model ---\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=hyperparameters.get('epochs', 10),\n",
    "        batch_size=hyperparameters.get('batch_size', 64),\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # The history.history dictionary contains a list of validation accuracies for each epoch.\n",
    "    val_accuracies = history.history['val_accuracy']\n",
    "\n",
    "    # Use Python's built-in max() function to find the highest value in that list.\n",
    "    best_validation_accuracy = max(val_accuracies)\n",
    "    \n",
    "    # Use the .index() method to find which epoch this occurred at.\n",
    "    # We add 1 because list indices are 0-based, but epochs are typically 1-based.\n",
    "    best_epoch = val_accuracies.index(best_validation_accuracy) + 1\n",
    "    # We subtract the 1 again from the best_epoch to obtain the associated training accuracy. \n",
    "    associated_train_acc = history.history['accuracy'][best_epoch - 1]\n",
    "\n",
    "    print(\"\\n--- Peak Performance Summary ---\")\n",
    "    print(f\"{'Best validation accuracy:':<35} {best_validation_accuracy:.4f}\")\n",
    "    print(f\"{'Associated training accuracy:':<35} {associated_train_acc:.4f}\")\n",
    "    print(f\"{'Occurred at epoch:':<35} {best_epoch}\")\n",
    "\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Sets ---\n",
    "\n",
    "# Experiment 1: Our baseline run\n",
    "mlp_exp_1_config = {\n",
    "    \"model_name\": \"MLP_Baseline_Run\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\":70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "# Experiment 2: A different setup with a lower learning rate, more epochs, and a smaller batch size\n",
    "mlp_exp_2_config = {\n",
    "    \"model_name\": \"MLP_Slow_Learn_Run\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "mlp_exp_3_config = {\n",
    "    \"model_name\": \"MLP_SGD_Learn_Run\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "mlp_exp_4_config = {\n",
    "    \"model_name\": \"MLP_SGD_Slow_Learn_Run\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67af808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the first experiment ---\n",
    "\n",
    "mlp_histories = []\n",
    "mlp_history_1 = run_experiment(\n",
    "    model_creation_func=create_mlp_model, \n",
    "    hyperparameters=mlp_exp_1_config,\n",
    "    parent_folder='MLP_Models',\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train\n",
    ")\n",
    "mlp_histories.append(mlp_history_1)\n",
    "\n",
    "# --- To run the second experiment, we just call it again with the other config :-)\n",
    "mlp_history_2 = run_experiment(\n",
    "    model_creation_func=create_mlp_model, \n",
    "    hyperparameters=mlp_exp_2_config,\n",
    "    parent_folder='MLP_Models',\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train\n",
    ")\n",
    "mlp_histories.append(mlp_history_2)\n",
    "\n",
    "mlp_history_3 = run_experiment(\n",
    "    model_creation_func=create_mlp_model, \n",
    "    hyperparameters=mlp_exp_3_config,\n",
    "    parent_folder='MLP_Models',\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train\n",
    ")\n",
    "mlp_histories.append(mlp_history_3)\n",
    "\n",
    "\n",
    "mlp_history_4 = run_experiment(\n",
    "    model_creation_func=create_mlp_model, \n",
    "    hyperparameters=mlp_exp_4_config,\n",
    "    parent_folder='MLP_Models',\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train\n",
    ")\n",
    "mlp_histories.append(mlp_history_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94357c",
   "metadata": {},
   "source": [
    "# Notes on Sparse Categorical Loss vs. Categorical Loss\n",
    "# Understanding Cross-Entropy Loss\n",
    "\n",
    "At its heart, **cross-entropy** is a concept from information theory that measures how different two probability distributions are. In the context of training a neural network for classification, we use it to measure the \"distance\" between the model's predicted probability distribution and the true probability distribution of the labels. The goal of training is to minimise this distance, effectively making the model's predictions more accurate (Goodfellow et al., 2016).\n",
    "\n",
    "---\n",
    "### Categorical Cross-Entropy (for One-Hot Labels)\n",
    "\n",
    "You use this loss function when your labels are explicitly **one-hot encoded** (e.g., the digit `3` is represented as `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`). The formula for a single sample is:\n",
    "\n",
    "$$L = -\\sum_{i=0}^{C-1} y_i \\log(\\hat{y}_i)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $C$ is the total number of classes (e.g., 10 for MNIST).\n",
    "-   $y_i$ is the ground truth (it is `1` for the correct class and `0` for all others).\n",
    "-   $\\hat{y}_i$ is the model's predicted probability for class $i$.\n",
    "\n",
    "Because the `y` vector is almost all zeros, the summation simplifies to just the negative logarithm of the probability the model assigned to the single correct class. For a label of `3`, the loss simply becomes $L = -\\log(\\hat{y}_3)$.\n",
    "\n",
    "---\n",
    "### Sparse Categorical Cross-Entropy (for Integer Labels)\n",
    "\n",
    "This is a more computationally and memory-efficient version used when your labels are simple **integers** (e.g., `3`). It arrives at the exact same mathematical result but skips the need for the one-hot encoded vector.\n",
    "\n",
    "The formula is a direct implementation of the simplified logic:\n",
    "\n",
    "$$L = -\\log(\\hat{y}_c)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $c$ is the integer representing the correct class (e.g., `c = 3`).\n",
    "-   $\\hat{y}_c$ is the model's predicted probability for that correct class $c$.\n",
    "\n",
    "As Chollet (2021) explains, both formulas compute the exact same value. The choice is purely a practical one based on the format of your labels, not a mathematical one that affects the model's learning.\n",
    "\n",
    "---\n",
    "**References**\n",
    "\n",
    "Chollet, F. (2021). *Deep learning with Python* (2nd ed.). Shelter Island, NY: Manning Publications.\n",
    "\n",
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep learning*. Cambridge, MA: MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7b25e",
   "metadata": {},
   "source": [
    "## Part 1, Task 2: Creating a simple Convolutional Neural Network (CNN)\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 1. Define the CNN BASE model Architecture ---\n",
    "# # We are building a Sequential model, which is a simple, linear stack of layers.\n",
    "# mnist_model_cnn: Sequential = Sequential([\n",
    "#     # This is our preprocessing layer for Z-score scaling (normalisation with mean 0 and std. dev 1).\n",
    "#     # It learns the mean and standard deviation from the training data and applies it.\n",
    "#     # The input_shape must match a single sample from our data, which is a 28x28 image.\n",
    "#     # We define the normalisation and flattening inside the model so that\n",
    "#     # they are applied consistently during both training and inference.\n",
    "\n",
    "#     Input(shape=(28, 28, 1)),   # Important note: We must now include the number of channels as well, because the core operation\n",
    "#     # of a convolution is to operate on volumes of data. The convolution slides a small filter (kernel) across the input image.\n",
    "#     # This filter itself has a depth and must match the depth (channels) of the input. It processes all channels simultaneously \n",
    "#     # to produce a single output value for that position, effectively combining spatial and channel-wise information.\n",
    "\n",
    "#     Normalization(),\n",
    "    \n",
    "#     # --- Convolutional Block 1 ---\n",
    "#     # Conv2D layers act as feature detectors. They scan the image with filters (kernels)\n",
    "#     # to find patterns like edges, curves, etc.\n",
    "#     # 32 filters: The number of features to learn.\n",
    "#     # (3, 3) kernel_size: The size of the scanning window.\n",
    "#     Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "#     # Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=1, activation='relu'),\n",
    "\n",
    "#     # MaxPooling2D downsamples the feature map, reducing dimensionality and making\n",
    "#     # the model more robust to variations in the position of features.\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "#     # --- Convolutional Block 2 ---\n",
    "#     # We add another Conv2D layer to learn more complex patterns from the features\n",
    "#     # detected by the first layer. It's common to increase the number of filters.\n",
    "#     Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "\n",
    "#     # The Flatten layer converts the 2D feature maps from the final pooling layer\n",
    "#     # into a 1D vector, preparing the data for the final classification layers.\n",
    "#     Flatten(),\n",
    "\n",
    "#     # --- Classification Head ---\n",
    "#     # A Dropout layer is added for regularisation. It randomly sets a fraction of\n",
    "#     # input units to 0 at each update during training, which helps prevent overfitting.\n",
    "#     Dropout(0.5), # (50% of the neurons will be dropped)\n",
    "#     # This Dense layer interprets the features extracted by the convolutional layers.\n",
    "#     Dense(units=128, activation='relu'),\n",
    "    \n",
    "#     # This is our output layer. It remains the same, with 10 neurons for digits 0-9\n",
    "#     # and 'softmax' to provide a probability distribution.\n",
    "#     Dense(units=10, activation='softmax')\n",
    "# ], name=\"CNN_Base\")\n",
    "\n",
    "# # We can print a summary of the model's architecture to see the layers and parameter counts.\n",
    "# print(\"\\n--- Model Architecture ---\")\n",
    "# mnist_model_cnn.summary()\n",
    "\n",
    "# # for n in range(len(mnist_model_cnn.layers)):\n",
    "# #     print(f\"MNIST model layer[{n}: {mnist_model_cnn.layers[n]}]\")\n",
    "\n",
    "# # --- 2. Adapt the Normalisation Layer ---\n",
    "# # Before training, we must let the Normalization layer calculate the mean and\n",
    "# # variance of our training data. The .adapt() method does this for us.\n",
    "# print(\"Adapting the normalisation layer to the training data...\")\n",
    "# mnist_model_cnn.layers[0].adapt(X_train) \n",
    "# print(\"Adaptation complete.\")\n",
    "\n",
    "\n",
    "# # --- 3. Configure and Compile the Model ---\n",
    "# # We configure the optimiser and the list of metrics we want to track.\n",
    "# adam_optimizer: Adam = Adam(learning_rate=0.001)\n",
    "# metrics_list: list = ['accuracy'] #, Precision(), Recall()] Precision and Recall can be used for Binary Classification problems only.\n",
    "\n",
    "# # The compile step brings everything together and prepares the model for training.\n",
    "# mnist_model_cnn.compile(\n",
    "#     optimizer=adam_optimizer,\n",
    "#     loss='sparse_categorical_crossentropy', # Best for integer labels in multi-class classification.\n",
    "#     metrics=metrics_list\n",
    "# )\n",
    "\n",
    "# # Define the filepath for the saved model.\n",
    "# # The placeholders {epoch:02d} and {val_accuracy:.4f} will be automatically filled in.\n",
    "# folder_name = 'CNN Models'\n",
    "# filepath = f'{folder_name}/best_{mnist_model_cnn.name}_epoch-{{epoch:02d}}_val_acc-{{val_accuracy:.4f}}.keras'\n",
    "\n",
    "# # Create a ModelCheckpoint callback so we can save the best model during training. Note: every epoch the model is evaluated\n",
    "# # on validation accuracy. If the validation accuracy improves, the model will be saved. If not, it will not be saved.\n",
    "# model_checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath=filepath,\n",
    "#     monitor='val_accuracy',      # Monitor the validation accuracy\n",
    "#     mode='max',                  # The direction of improvement (higher is better for accuracy). Had we chosen Min, then we would be looking for the lowest validation accuracy. \n",
    "#     save_best_only=True,         # Only save the model if `val_accuracy` has improved\n",
    "#     verbose=1                    # Print a message when the model is saved\n",
    "# )\n",
    "\n",
    "# # --- 4. Train the Model ---\n",
    "# # This is where the learning happens. The .fit() method trains the model on our data.\n",
    "# # The 'history' object will store the loss and metric values for each epoch.\n",
    "# history_cnn: History = mnist_model_cnn.fit(\n",
    "#     X_train,\n",
    "#     Y_train,\n",
    "#     epochs=5,\n",
    "#     validation_split=0.1, # We hold back 10% of the training data to validate performance.\n",
    "#     batch_size=64,\n",
    "#     verbose=1, # We set verbose=1 to see the training progress bar.\n",
    "#     callbacks=[model_checkpoint_callback],  # We add the callback here in the fit method so that we can save the best model during training.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the base CNN model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Normalization(input_shape=(28, 28, 1)),\n",
    "        \n",
    "        # --- Convolutional Block 1 ---\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6292216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Set for the Base CNN ---\n",
    "cnn_exp_1_config = {\n",
    "    \"model_name\": \"CNN_Base\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "cnn_exp_2_config = {\n",
    "    \"model_name\": \"CNN_Slow_Learn\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "cnn_exp_3_config = {\n",
    "    \"model_name\": \"CNN_SGD\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "cnn_exp_4_config = {\n",
    "    \"model_name\": \"CNN_SGD_Slow_Learn\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the CNN experiment ---\n",
    "cnn_histories = []\n",
    "cnn_history_1 = run_experiment(\n",
    "    model_creation_func=create_cnn_model, \n",
    "    hyperparameters=cnn_exp_1_config,\n",
    "    parent_folder='CNN_Models',\n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "cnn_histories.append(cnn_history_1)\n",
    "\n",
    "cnn_history_2 = run_experiment(\n",
    "    model_creation_func=create_cnn_model, \n",
    "    hyperparameters=cnn_exp_2_config,\n",
    "    parent_folder='CNN_Models',\n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "cnn_histories.append(cnn_history_2)\n",
    "\n",
    "cnn_history_3 = run_experiment(\n",
    "    model_creation_func=create_cnn_model, \n",
    "    hyperparameters=cnn_exp_3_config,\n",
    "    parent_folder='CNN_Models',\n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "cnn_histories.append(cnn_history_3)\n",
    "\n",
    "cnn_history_4 = run_experiment(\n",
    "    model_creation_func=create_cnn_model, \n",
    "    hyperparameters=cnn_exp_4_config,\n",
    "    parent_folder='CNN_Models',\n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "cnn_histories.append(cnn_history_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c387c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Plotting Function ---\n",
    "def plot_training_history(history: History):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy']) # the train accuracy\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{history.model.name} model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss']) # the train loss\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{history.model.name} model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08790f",
   "metadata": {},
   "source": [
    "### Plot the results of every epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_histories(histories):\n",
    "    for history in histories:\n",
    "        plot_training_history(history)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "print_training_histories(mlp_histories)\n",
    "print_training_histories(cnn_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab5e2",
   "metadata": {},
   "source": [
    "## Testing the models on the held-out test set\n",
    "We test the model on the test data, which is data that the model has never seen before. Then we verify the model's real-world accuracy. It is expected that this does not deviate much from the validation sets, because the MNIST dataset contains images that are very clean and simple:\n",
    "- They are small (28 x 28 pixels only).\n",
    "- The digits are centered and normalised in size.\n",
    "- The background is a solid colour with no distracting noise.\n",
    "  \n",
    "Because of this simplicity, the patterns that differentiate one digit from another (e.g., a \"1\" is a vertical line, an \"8\" is two loops) are very strong and easy for our model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af8a5",
   "metadata": {},
   "source": [
    "First we define a function that browser to a folder with saved models, extracts the file with the highest validation accuracy in its name, loads it and tests it with the held-out X_test and Y_test. \n",
    "\n",
    "A function is convenient because we will use it on different models, with different hyperparameters and hence, avoid repetition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_load_and_analyse_best_model(\n",
    "    parent_folder: str, # Changed name for clarity\n",
    "    x_test_data: NDArray[np.float32], \n",
    "    y_test_data: NDArray[np.int_]\n",
    ") -> Tuple[tf.keras.Model | None, float | None, float | None]:\n",
    "    \"\"\"\n",
    "    Recursively searches through all subfolders in a parent directory to find the\n",
    "    single best Keras model, then loads and analyses it.\n",
    "    \"\"\"\n",
    "    best_model_path = None # We will now store the full path directly\n",
    "    best_val_accuracy = -1.0\n",
    "\n",
    "    pattern = re.compile(r\"val_acc-([\\d.]+)\\.keras\")\n",
    "\n",
    "    if not os.path.isdir(parent_folder):\n",
    "        print(f\"Error: Parent directory not found at '{parent_folder}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    # --- NEW: Use os.walk() to search through all subdirectories ---\n",
    "    # os.walk() goes through a directory tree top-down.\n",
    "    for dirpath, _, filenames in os.walk(parent_folder):\n",
    "        for filename in filenames:\n",
    "            match = pattern.search(filename)\n",
    "            if match:\n",
    "                val_accuracy = float(match.group(1))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    # Construct and store the full path to this new best model\n",
    "                    best_model_path = os.path.join(dirpath, filename)\n",
    "    \n",
    "    # The rest of the function works perfectly, we just need to use best_model_path\n",
    "    if best_model_path:\n",
    "        print(f\"Found and loading best model across all experiments: {best_model_path}\")\n",
    "        \n",
    "        loaded_model = tf.keras.models.load_model(best_model_path)\n",
    "        \n",
    "        # --- Print Compiled Hyperparameters ---\n",
    "        print(\"\\n--- Key Hyperparameters ---\")\n",
    "        # Gets the configuration of the model's optimiser.\n",
    "        optimiser_config = loaded_model.optimizer.get_config()\n",
    "        optimiser_name = optimiser_config['name']\n",
    "        learning_rate = optimiser_config['learning_rate']\n",
    "        \n",
    "        # Gets the name of the loss function the model was compiled with.\n",
    "        loss_function = loaded_model.loss\n",
    "        \n",
    "        print(f\"{'Optimiser:':<20} {optimiser_name}\")\n",
    "        print(f\"{'Learning Rate:':<20} {learning_rate}\")\n",
    "        print(f\"{'Loss Function:':<20} {loss_function}\")\n",
    "        \n",
    "        # Prints a summary table of the model's architecture.\n",
    "        print(\"\\n--- Best Model Summary (Architecture) ---\")\n",
    "        loaded_model.summary()\n",
    "\n",
    "        # Evaluates the loaded model's performance on the unseen test data.\n",
    "        print(\"\\n--- Evaluating model performance on the test set ---\")\n",
    "        loss, accuracy = loaded_model.evaluate(x_test_data, y_test_data, verbose=1)\n",
    "        \n",
    "        # Prints the final evaluation results, formatted to 4 decimal places.\n",
    "        print(f\"\\nTest Set Loss: {loss:.4f}\")\n",
    "        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # --- Generate Detailed Performance Analysis ---\n",
    "        print(\"\\n--- Detailed Analysis ---\")\n",
    "        \n",
    "        # Use the model to predict the class for each image in the test set.\n",
    "        y_pred_probabilities = loaded_model.predict(x_test_data)\n",
    "        # The model outputs probabilities; we use np.argmax to find the class with the highest probability.\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "        # Generate and print a text report showing precision, recall, and f1-score for each digit.\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        report = classification_report(y_test_data, y_pred, target_names=[str(i) for i in range(10)])\n",
    "        print(report)\n",
    "\n",
    "        # Generate and plot a confusion matrix to visualise which digits are being confused.\n",
    "        print(\"\\n--- Confusion Matrix ---\")\n",
    "        cm = confusion_matrix(y_test_data, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('Actual Label')\n",
    "        plt.title(f'Confusion Matrix for {loaded_model.name}')\n",
    "        plt.show()\n",
    "        \n",
    "        # Returns the loaded model object and its performance metrics for potential further use.\n",
    "        return loaded_model, accuracy, loss\n",
    "    else:\n",
    "        # If no model files matching the pattern were found, print a message and return nothing.\n",
    "        print(f\"No model files found in any subfolders of '{parent_folder}'.\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24f712",
   "metadata": {},
   "source": [
    "### Testing the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder=\"MLP_Models\"\n",
    "# To capture the output, assign it to variables\n",
    "best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "    parent_folder=model_folder,\n",
    "    x_test_data=X_test,\n",
    "    y_test_data=Y_test\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2e325",
   "metadata": {},
   "source": [
    "### Testing the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder='CNN_Models'\n",
    "# To capture the output, assign it to variables\n",
    "best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "    parent_folder=model_folder,\n",
    "    x_test_data=X_test,\n",
    "    y_test_data=Y_test\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9820dc3",
   "metadata": {},
   "source": [
    "# Future to do's (not part of this assessment)\n",
    "- Implement KerasTuner, to automatically train and test models with a plethora of hyperparamaters, optimisers, loss functions:\n",
    "\n",
    "We first need to install it first: uv pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"This is our hypermodel, which defines the search space.\"\"\"\n",
    "    \n",
    "    model = Sequential(name=\"Tuned_MLP\")\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Normalization())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # --- Define Hyperparameters to Tune ---\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    # Tune the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Add the output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # --- Compile the model inside the function ---\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "--- Set up the Tuner ---\n",
    "### We'll use RandomSearch, which randomly tries combinations.\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # The total number of model variations to test\n",
    "    executions_per_trial=2, # The number of times to train each model variation\n",
    "    directory='tuning_results',\n",
    "    project_name='MNIST_Tuning'\n",
    ")\n",
    "\n",
    "### --- Start the Search ---\n",
    "### This is like model.fit(), but it runs the whole tuning process.\n",
    "tuner.search(X_train, Y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "### --- Get the Best Model ---\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\n--- Best Hyperparameters Found ---\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "print(\"\\n--- Evaluating the Best Model Found by the Tuner ---\")\n",
    "best_model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_NN_MNIST (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
