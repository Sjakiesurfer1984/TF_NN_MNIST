{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df21c37f",
   "metadata": {},
   "source": [
    "# CSE5ML: Machine Learning\n",
    "# Assessment 2: Image Classification with Neural Networks\n",
    "\n",
    "## Completion Requirements\n",
    "\n",
    "- **Working code and written report**\n",
    "- **Due date:** 11.59 pm (AEST), Sunday 14 September 2025 (Week 7)\n",
    "- **Weighting:** 30%\n",
    "- **Length:** Working code and 1000-word report (+/‚Äì 10%)\n",
    "- **SILOs:** Implement a neural network with different learning algorithms for time-series forecasting with real-world data from industry (SILO 4).\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this assessment is to develop hands-on experience with neural networks for image classification ‚Äì a key application of machine learning used across industries such as health care, autonomous systems and digital security to interpret and act on visual data.\n",
    "\n",
    "## Task Details\n",
    "\n",
    "This assessment aims to consolidate your knowledge and practical skills to build neural networks (NNs) for supervised learning. The task is formulated as a multi-class classification problem for handwritten images, and the goal is to model the relationship between the images‚Äô content, network structure and labels. You need to provide:\n",
    "\n",
    "- **Working code** (part 1)\n",
    "- **A written report** of 1000 words on the method and results (part 2).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "The MNIST database is a dataset with handwritten digits (from 0 to 9). The digits have been size-normalised and centred in a fixed-size image (28 √ó 28 pixels) with values from 0 to 1. You can use the following code with TensorFlow in Python to download the data.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We will call the images ùë• and the labels ùë¶. Both the training set and test set contain ùë• and ùë¶.\n",
    "Each image is 28 pixels by 28 pixels.\n",
    "As mentioned, the corresponding labels in the MNIST are numbers between 0 and 9, describing which digit a given image represents. In this assessment, we regard the labels as one-hot vectors; that is, 0 in most dimensions, and 1 in a single dimension. In this case, the ùëõ-th digit will be represented as a vector, which is 1 in the ùëõ dimensions. For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n",
    "The assessment aims to build NNs for classifying handwritten digits in the MNIST database, train it on the training set and test it on the test set. Since the main object of this assessment is for you to understand the relationship between input, model and output, you are not expected to achieve very high accuracy in model performance; instead, for each task, you should be able to identify how you can improve model performance with the change of network structure.\n",
    "\n",
    "There are two parts to this assessment:\n",
    "\n",
    "### Part 1\n",
    "Part 1 is comprised of three main tasks:\n",
    "\n",
    "**Task 1**\n",
    "\n",
    "Build a neural network without convolutional layers to do the classification task (hint: you will need the use of dense layers). Then you can change the model structure (i.e. number of dense layers, number of neurons in dense layers or activation functions) to be able to improve network performance.\n",
    "\n",
    "**Task 2**\n",
    "\n",
    "Build a neural network with the use of convolutional layers (you can decide other layer types you want to include in your network). Then you can change the number of convolutional layers and the number of filters or activation functions in the convolutional layers to be able to improve network performance.\n",
    "\n",
    "**Task 3**\n",
    "\n",
    "Change the type of optimiser or learning rate that you applied in the previous tasks and see how these changes can influence model performance. (You can keep the final network structure you applied in task 2 and try at least one different optimiser setting.)\n",
    "Please read the following comments and requirements very carefully before starting the assessment:\n",
    "1.\tThe assessment is based on the content of labs and Weeks 1‚Äì3.\n",
    "2.\tIn Week 1 we talked about the use of training set, validation set and test set in machine learning. In this assessment, you are asked to train the NN on the training set and test the NN on the test set, without any given validation set. (If you want to monitor the training process, you can also try what we did in Week 3: you can consider the validation set is the same as the test set in this assessment.)\n",
    "3.\tIn the assessment, the performance of an NN is measured by its prediction accuracy in classifying images from the test set (i.e. number of the correctly predicted images/number of the images in the test set).\n",
    "4.\tSince the MNIST dataset is a black-and-white image dataset, the shape of dataset is (dataset_length, 28,28). But to fit it into a conv2d layer, we need to make the input shape comply with its required format: (batch_size, image_width, image_depth, image_channels). Although batch_size can be decided later when you train it, you will still need to tell the number of image channels here. You can consider reshaping the dataset into (dataset_length, 28,28,1) or add one more dimension at the end with np.newaxis.\n",
    "5.\tYou are expected to show at least two models in for tasks 1 and 2: one for the model you start with, and another model is the model that you identified to have better accuracy. For task 3, you need to show what optimiser and/or learning rate you applied.\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Your report must at least contain the following content:\n",
    "1.\tYour name and student number.\n",
    "2.\tArchitectures of the NNs, with figures for tasks 1 and 2.\n",
    "3.\tDescription on the optimiser and learning rate you applied in the final model of task 2 and the optimiser or change of learning rate you used in task 3.\n",
    "4.\tExperiments and performances, with parameter setting.\n",
    "5.\tDiscussion on the improvement/deterioration of the NN‚Äôs performance after changing the architecture and parameter setting for each task and findings of comparing the results from all three tasks.\n",
    "6.\tThe ranking of all NNs‚Äô performances from all the three tasks.\n",
    "\n",
    "### Assessment criteria\n",
    "\n",
    "This assessment will measure your ability to:\n",
    "\n",
    "**Part 1:**\n",
    "\n",
    "‚Ä¢\tdescribe the two models, experiment settings and compare the results for task 1 (25%)\n",
    "‚Ä¢\tdescribe the two models, experiment settings and compare the results for task 2 (25%)\n",
    "‚Ä¢\tdescribe the two optimisers or learning rates, experiment settings and compare the results for task 3 (35%)\n",
    "\n",
    "**Part 2:**\n",
    "\n",
    "‚Ä¢\tdemonstrate correct code quality (10%)\n",
    "‚Ä¢\tresearch extensively and demonstrate depth of thinking; produce a well-structured report (5%).\n",
    "Refer to the marking guide for marking and feedback information.\n",
    "\n",
    "### Submission details\n",
    "\n",
    "The submitted assessment consists of (1) a report (in PDF format) of no less than 1000 words and (2) all codes for modelling, training and testing the NN with TensorFlow in Python (you can choose to have one code file including all your codes, or you can have one code file for each task separately).\n",
    "**If you use ChatGPT or other generative AI tools, you must cite them and clearly indicate your original contributions.**\n",
    "\n",
    "In keeping with La Trobe University policy, all assignments are to be submitted in Moodle via Turnitin.\n",
    "To be accepted, your assessment submission **must** generate a similarity score (you are responsible for checking this). Submitting in Word or PDF format is the best way to do this. If your submission does not generate a similarity score, it cannot be checked for plagiarism and therefore **will not be marked.**\n",
    "\n",
    "Last modified: Tuesday, 12 August 2025, 8:58 PM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a43b04",
   "metadata": {},
   "source": [
    "# Part 1, task 1 & 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85a5a6",
   "metadata": {},
   "source": [
    "### Import relevant dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the MNIST dataset from Keras, a classic collection of 70,000 grayscale images of handwritten digits (0-9).\n",
    "from keras.datasets import mnist \n",
    "\n",
    "# Imports TensorFlow, the core open-source library from Google for building and training machine learning models. We use the alias 'tf' by convention.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Imports the Adam optimiser. An optimiser is an algorithm that adjusts the model's internal parameters (weights) to minimise the error, and Adam is a popular, efficient choice.\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Imports specific performance metrics. Metrics are used to evaluate how well the model is performing.\n",
    "# Precision: Measures the accuracy of positive predictions.\n",
    "# Recall: Measures the model's ability to find all the actual positive instances.\n",
    "# Accuracy: Measures the overall fraction of correct predictions.\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "\n",
    "# Imports the History callback object. A 'callback' is a function that can be executed at different stages of training. The History object automatically records the metrics and loss values from each epoch.\n",
    "from tensorflow.python.keras.callbacks import History\n",
    "\n",
    "# Imports the ModelCheckpoint callback. This callback saves the model to a file during training, typically only when its performance on a validation metric improves.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Imports the Pandas library, a powerful tool for data manipulation and analysis. It's mainly used for working with structured data in tables called DataFrames. 'pd' is the standard alias.\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the Sequential model type from Keras. This is the simplest way to build a model, by creating a linear stack of layers.\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Imports different types of layers, which are the fundamental building blocks of a neural network.\n",
    "# Dense: A standard, fully-connected layer where each neuron is connected to every neuron in the previous layer.\n",
    "# Input: A special layer used to define the shape and data type of the model's input.\n",
    "# Flatten: A layer that transforms a multi-dimensional input (like a 2D image) into a one-dimensional vector.\n",
    "# Normalization: A preprocessing layer that scales input data to a standard range (e.g., mean of 0, standard deviation of 1), which helps the model train faster. \n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Normalization, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Imports a utility function from scikit-learn, a popular library for traditional machine learning. train_test_split is used to split a single dataset into separate training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports the pyplot interface from Matplotlib, which is the most widely used library for creating plots and visualisations in Python. 'plt' is the standard alias.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports the NumPy library, which is the foundation for numerical computing in Python. It provides support for large, multi-dimensional arrays and a wide range of mathematical functions. 'np' is the standard alias.\n",
    "import numpy as np\n",
    "\n",
    "# Imports a data scaling tool from scikit-learn. MinMaxScaler scales all data features to a specific range, usually 0 to 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Imports tools for 'type hinting' from Python's typing module. Type hints make code more readable and can be used by external tools to check for errors.\n",
    "# Tuple: Used to hint that a variable or function return is a tuple (an ordered, immutable collection of elements).\n",
    "from typing import Tuple\n",
    "\n",
    "# Imports a specific type hint from NumPy's typing module.\n",
    "# NDArray: Used to hint that a variable is a NumPy n-dimensional array, which is more descriptive than a generic type.\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Imports the 'os' module. This library provides a way for Python to interact with the computer's underlying operating system.\n",
    "# We use it for tasks like reading file names from a folder (os.listdir()) and constructing file paths that work correctly on any system, like Windows, Mac, or Linux (os.path.join()).\n",
    "import os \n",
    "\n",
    "# Imports the 're' module, which stands for Regular Expression. This is Python's library for advanced pattern matching in strings.\n",
    "# We use it to find and extract specific pieces of text from a string, like pulling the accuracy score out of a complex filename (e.g., finding '0.9935' in 'model_acc-0.9935.keras').\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ce86f",
   "metadata": {},
   "source": [
    "### Define the training set features (X_train) and target variable (Y_train) as well as the test set features (X_test_) and target variable (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b32fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset, which is a large database of handwritten digits.\n",
    "# The function returns two tuples: one for training data and one for testing data.\n",
    "# Recalling, a Tuple is a collection of objects that are ordered and immutable.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# First we convert the data to float32, which helps with numerical stability. A float32 provides sufficient precision, while also being memory efficient.\n",
    "# Most modern CPU's and GPU's are optimized for float32 operations, making computations faster.\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# Then we convert the training data to have a channel dimension, which is required for CNNs.\n",
    "X_train = X_train[..., tf.newaxis] # Add the channel dimension\n",
    "X_test = X_test[..., tf.newaxis] # Add the channel dimension\n",
    "print(f\"New shape for X_train for CNN's: {X_train.shape}\")\n",
    "print(f\"New shape for X_test for CNN's: {X_test.shape}\")\n",
    "\n",
    "# Declare the types of the loaded data for clarity.\n",
    "X_train: NDArray[np.float32]\n",
    "Y_train: NDArray[np.uint8]\n",
    "X_test: NDArray[np.float32]\n",
    "Y_test: NDArray[np.uint8]\n",
    "\n",
    "# We set the line width to a large value to avoid line breaks when printing the array.\n",
    "with np.printoptions(linewidth=10000):\n",
    "    # Print the shapes of the datasets to understand their dimensions.\n",
    "    print(\"Shape of X_train:\\t\", X_train.shape)\n",
    "    print(\"Shape of X_test:\\t\", X_test.shape)\n",
    "    print(\"Shape of Y_train:\\t\", Y_train.shape)\n",
    "    print(\"Shape of Y_test:\\t\", Y_test.shape)\n",
    "    print(f\"X_train data type: {X_train.dtype}\")\n",
    "    print(f\"X_test data type: {X_test.dtype}\")\n",
    "    print(f\"Y_train data type: {Y_train.dtype}\")\n",
    "    print(f\"Y_test data type: {Y_test.dtype}\")\n",
    "\n",
    "    # Inspect a single data sample to see what it looks like.\n",
    "    n: int = 567\n",
    "    print(f\"\\nX_train data {n}-th element (a 28x28 pixel image):\\n\", np.squeeze(X_train[n]))\n",
    "    print(\"\\nAnd its corresponding label:\\t\", Y_train[n])\n",
    "\n",
    "    # TODO: For using this data in a neural network,\n",
    "    # Tensorflow/Keras expects the input data to be in a 1D or 2D array format where each row represents a single sample and each column represents a feature. The general format for the input shape is: (batch_size, feature_1, feature_2, ...)\n",
    "    # However, we can use the tf.keras.layers.Flatten layer as the first layer in our sequential model.\n",
    "    # This layer automatically flattens the input shape without the need for manual reshaping of our data.\n",
    "    # For a Dense (fully connected) network: We must flatten each 28x28 image into a single 1D array of 784 pixels. The input shape for the first layer of our model would then be (None, 784), where None represents a variable batch size.\n",
    "    # For a Convolutional Neural Network (CNN): We must add a channel dimension. Since the images are grayscale, there is only one channel. We would reshape the data to (number_of_images, 28, 28, 1). The input shape for the first layer (typically a Conv2D layer) would be (28, 28, 1). The batch size is handled automatically by Keras.\n",
    "    # Scaling can also be performd in the model using a tf.keras.layers.Rescaling or keras.layers.Normalization layer as the first layer in our sequential model.\n",
    "    # The advantage of using these layers is that they integrate seamlessly into the model architecture, ensuring that the data is preprocessed consistently during both training and inference.\n",
    "    # This approach also simplifies the code by reducing the need for separate preprocessing steps outside the model definition.\n",
    "    # And, it ensures that inference data is processed in the same way as training data, which is crucial for maintaining model performance.\n",
    "\n",
    "    # Analyze the distribution of the digits in the training set.\n",
    "    # `np.unique` finds the unique digit labels and `return_counts=True` counts their occurrences.\n",
    "    dataset_train_distribution: Tuple[np.ndarray, np.ndarray] = np.unique(Y_train, return_counts=True)\n",
    "    digits_train: np.ndarray = dataset_train_distribution[0]\n",
    "    counts_train: np.ndarray = dataset_train_distribution[1]\n",
    "    \n",
    "    print(\"\\n--- Train Dataset Distribution ---\")\n",
    "    print(\"Digits:\\t\\t\\t\", digits_train)\n",
    "    print(\"Count per digit:\\t\", counts_train)\n",
    "    \n",
    "    # Calculate basic statistics on the distribution.\n",
    "    avg: float = np.mean(counts_train)\n",
    "    print(f\"Average sample size:\\t {avg:.2f}\")\n",
    "    \n",
    "    max_count_train: np.int64 = np.max(counts_train)\n",
    "    min_count_train: np.int64 = np.min(counts_train)\n",
    "    print(f\"Maximum sample size:\\t {max_count_train}\")\n",
    "    print(f\"Minimum sample size:\\t {min_count_train}\")\n",
    "\n",
    "\n",
    "    dataset_test_distribution: Tuple[np.ndarray, np.ndarray] = np.unique(Y_test, return_counts=True)\n",
    "    digits_test: np.ndarray = dataset_test_distribution[0]\n",
    "    counts_test: np.ndarray = dataset_test_distribution[1]\n",
    "    \n",
    "    print(\"\\n--- Test Dataset Distribution ---\")\n",
    "    print(\"Digits:\\t\\t\\t\", digits_test)\n",
    "    print(\"Count per digit:\\t\", counts_test)\n",
    "    \n",
    "    # Calculate basic statistics on the distribution.\n",
    "    avg: float = np.mean(counts_test)\n",
    "    print(f\"Average sample size:\\t {avg:.2f}\")\n",
    "    \n",
    "    max_count_test: np.int64 = np.max(counts_test)\n",
    "    min_count_test: np.int64 = np.min(counts_test)\n",
    "    print(f\"Maximum sample size:\\t {max_count_test}\")\n",
    "    print(f\"Minimum sample size:\\t {min_count_test}\")\n",
    "\n",
    "# Create a bar chart from the counts and digits to visualize the distribution.\n",
    "plt.bar(digits_train, counts_train, color='blue', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for clarity.\n",
    "plt.title('Count of Each Digit in Training Set')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Set x-ticks to be at the center of each bar and label them with the digit.\n",
    "# Minor ticks are used here to place the labels directly under the bars.\n",
    "# Ticks specify the positions on the x-axis where the labels should be placed.\n",
    "# By setting ticks=digits_train, we ensure that each digit (0-9) is labeled correctly under its corresponding bar.\n",
    "plt.xticks(ticks=digits_train, minor=True, labels=digits_train)\n",
    "\n",
    "# Add a grid for better readability.\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()\n",
    "\n",
    "# And the same bar chart for the test set.\n",
    "\n",
    "# Create a bar chart from the counts and digits to visualize the distribution.\n",
    "plt.bar(digits_test, counts_test, color='red', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for clarity.\n",
    "plt.title('Count of Each Digit in Test Set')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Set x-ticks to be at the center of each bar and label them with the digit.\n",
    "plt.xticks(ticks=digits_test, minor=True, labels=digits_test)\n",
    "\n",
    "# Add a grid for better readability.\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d4acf",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "The content and size of the training and testing datasets align with the description on the Kaggle MNIST dataset page, Hojjat, F. (2017). MNIST: The Most Famous Dataset in the World. Kaggle. Retrieved August 28, 2025, from https://www.kaggle.com/datasets/hojjatk/mnist-dataset. The plot of digit distribution shows a fairly homogeneous representation across all classes (digits 0 through 9). While the digit '1' is slightly oversampled and the digit '5' is slightly undersampled, the class imbalance is not significant enough to warrant further action for this assessment.\n",
    "\n",
    "In a scenario where the distribution were to be significantly imbalanced and we needed to make it more homogeneous, we would use a technique called **resampling**. Resampling involves adjusting the distribution of the training data to be more balanced. There are two primary types:\n",
    "\n",
    "- **Oversampling** involves duplicating samples from the underrepresented classes to increase their frequency.\n",
    "\n",
    "- **Undersampling** involves removing samples from the overrepresented classes to reduce their frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5568184",
   "metadata": {},
   "source": [
    "## Part 1, Task 1: Creating a simple Multilayer Perceptron (MLP) neural network\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set Seeds for Reproducibility ---\n",
    "\n",
    "# This sets the global random seed for all TensorFlow operations.\n",
    "# It ensures that things like model weight initialisation are the same every time.\n",
    "# `tf.random.set_seed()` is the modern way to do this in TensorFlow 2.\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# This sets the random seed for all NumPy operations.\n",
    "# This is important if we are creating our data using NumPy or using any\n",
    "# NumPy functions that involve randomness.\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_mlp_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'), # Relu is the goto activation function. We could also use LeakyRelu, \n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954def66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wide_mlp_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=512, activation='relu'),\n",
    "        Dense(units=1024, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_mlp_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_creation_func, hyperparameters, parent_folder, X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Runs a full training experiment for a given model architecture and hyperparameter set.\n",
    "    \"\"\"\n",
    "    # Create the model instance first.\n",
    "    model = model_creation_func()\n",
    "    model.name = hyperparameters.get('model_name', 'unnamed_model')\n",
    "\n",
    "    # --- Adapt the Normalisation Layer ---\n",
    "    print(\"\\nAdapting the normalisation layer...\")\n",
    "    # The adapt method is now called here, before the model is compiled or trained.\n",
    "    model.layers[0].adapt(X_train)\n",
    "    print(\"Adaptation complete.\\n\")\n",
    "\n",
    "    print(f\"\\n--- Starting Experiment: {model.name} ---\")\n",
    "\n",
    "    # We can print a summary of the model's architecture to see the layers and parameter counts.\n",
    "    print(\"\\n--- Model Architecture ---\")\n",
    "    model.summary()\n",
    "    # Generate the model's diagram as an image file\n",
    "    plot_model(model, to_file=f'{model.name}_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # And we can also print the hyperparameters of the model.\n",
    "    print(\"\\n--- Hyperparameters ---\")\n",
    "    for key, value in hyperparameters.items():\n",
    "        print(f\"{key:<20}: {value}\")\n",
    "\n",
    "    # --- Initialise WandB Run and Callbacks ---\n",
    "    # The callbacks and WandB run are configured AFTER the model is fully built and adapted.\n",
    "    # This is important because the WandBMetricsLogger callback inspects the model to log its architecture and parameters.\n",
    "    # The run_name includes the model name, learning rate, batch size, and a timestamp for uniqueness.\n",
    "    run_name = f\"{model.name}-lr_{hyperparameters.get('learning_rate', 0.001)}-bs_{hyperparameters.get('batch_size', 64)}-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    # local_log_dir = os.path.join(os.getcwd(), \"wandb\", run_name)\n",
    "    local_log_dir = os.path.join(os.getcwd(), \"wandb\")\n",
    "    os.makedirs(local_log_dir, exist_ok=True)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"CSE5ML-Assessment2\",\n",
    "        name=run_name,\n",
    "        config=hyperparameters,\n",
    "        dir=local_log_dir,\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(parent_folder, \"logs\", model.name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    wandb_metrics_logger = WandbMetricsLogger()\n",
    "\n",
    "    # --- Configure the Optimiser ---\n",
    "    optimiser_name = hyperparameters.get('optimiser', 'adam').lower() # Default to 'adam' if not specified\n",
    "    learning_rate = hyperparameters.get('learning_rate', 0.001) # Default to 0.001 if not specified\n",
    "\n",
    "    if optimiser_name == 'adam':\n",
    "        optimiser = Adam(learning_rate=learning_rate) # We use the Adam Object rather than the string 'adam' to be explicit. The difference is that we can see the learning rate in the model summary.\n",
    "    elif optimiser_name == 'sgd':\n",
    "        optimiser = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimiser = optimiser_name\n",
    "\n",
    "    # --- Configure the ModelCheckpoint Callback ---\n",
    "    model_specific_folder = os.path.join(parent_folder, model.name) # This creates a sub-folder for each model type under the parent folder.\n",
    "    os.makedirs(model_specific_folder, exist_ok=True) # exist_ok=True avoids an error if the folder already exists.\n",
    "    filepath = os.path.join(model_specific_folder, 'best_model_epoch-{epoch:02d}_val_acc-{val_accuracy:.4f}.keras') #The filepath now includes the model name, the best epoch and validation accuracy as a sub-folder.\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1 # Only print messages when the model improves\n",
    "    )\n",
    "\n",
    "    # Configure the EarlyStopping callback\n",
    "    # - monitor='val_loss': Watch the validation loss.\n",
    "    # - patience=3: Stop training if val_loss doesn't improve for 3 consecutive epochs.\n",
    "    # - restore_best_weights=True: Restore model weights from the epoch with the best val_loss.\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', # we track the loss, because this tells us: how certain the model is about its predictions, rather than just saying whether it was right or wrong. E.g.: 51% confindence the digit is a 2. So accuracy = 100% - but it's not very sure.\n",
    "        patience=10, # We use a patience of 10 epochs to allow the model more time to improve, especially with a lower learning rate.\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Compile the Model ---\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss=hyperparameters.get('loss_function', 'sparse_categorical_crossentropy'),\n",
    "        metrics=['accuracy'] # For multi-class classification, 'accuracy' is appropriate. However, we could also add Precision() and Recall() here if needed.\n",
    "    )\n",
    "\n",
    "    # --- Train the Model ---\n",
    "    # history is a History object that contains details about the training process, including the loss and accuracy for each epoch.\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=hyperparameters.get('epochs', 10),\n",
    "        batch_size=hyperparameters.get('batch_size', 64),\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint, wandb_metrics_logger, tensorboard_callback, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # The history.history dictionary contains a list of validation accuracies for each epoch.\n",
    "    val_accuracies = history.history['val_accuracy']\n",
    "    best_validation_accuracy = max(val_accuracies)\n",
    "    best_epoch = val_accuracies.index(best_validation_accuracy) + 1\n",
    "    associated_train_acc = history.history['accuracy'][best_epoch - 1]\n",
    "\n",
    "    print(\"\\n--- Peak Performance Summary ---\")\n",
    "    print(f\"{'Best validation accuracy:':<35} {best_validation_accuracy:.4f}\")\n",
    "    print(f\"{'Associated training accuracy:':<35} {associated_train_acc:.4f}\")\n",
    "    print(f\"{'Occurred at epoch:':<35} {best_epoch}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Sets ---\n",
    "\n",
    "mlp_epochs = 100\n",
    "mlp_batch_size = 128\n",
    "# Experiment 1: Our baseline run\n",
    "mlp_exp_1_config = {\n",
    "    \"model_name\": \"MLP_Baseline_Adam\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": mlp_epochs,\n",
    "    \"batch_size\": mlp_batch_size\n",
    "}\n",
    "\n",
    "# Experiment 2: Same as the MLP_Baseline but with a lower learning rate\n",
    "mlp_exp_2_config = {\n",
    "    \"model_name\": \"MLP_Baseline_Adam_Slow_Learn\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": mlp_epochs,\n",
    "    \"batch_size\": mlp_batch_size,\n",
    "}\n",
    "\n",
    "# Experiment 3: Same as the MLP_Baseline but with a different optimizer (SGD)\n",
    "mlp_exp_3_config = {\n",
    "    \"model_name\": \"MLP_Baseline_SGD_Learn\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": mlp_epochs,\n",
    "    \"batch_size\": mlp_batch_size,\n",
    "}\n",
    "\n",
    "# Experiment 4: Same as the MLP_Baseline but with a different optimizer (SGD) and a lower learning rate\n",
    "mlp_exp_4_config = {\n",
    "    \"model_name\": \"MLP_Baseline_SGD_Slow_Learn\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": mlp_epochs,\n",
    "    \"batch_size\": mlp_batch_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67af808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the first experiment ---\n",
    "train_mlp = True\n",
    "if train_mlp:\n",
    "    mlp_histories = []\n",
    "    mlp_history = run_experiment(\n",
    "        model_creation_func=create_base_mlp_model, \n",
    "        hyperparameters=mlp_exp_1_config, \n",
    "        parent_folder='MLP_Models',\n",
    "        X_train=X_train,\n",
    "        Y_train=Y_train\n",
    "    )\n",
    "    mlp_histories.append(mlp_history)\n",
    "\n",
    "# # --- To run the second experiment, we just call it again with a different config (hyper parameter set) :-)\n",
    "# --- We first  test different model architectures before running more experiments with different hyperparameters (Part 1 Task 1 & 2). ---\n",
    "# --- THen we test the best performing model of Part 1 Task 1& 2 with different hyperparameters. ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94357c",
   "metadata": {},
   "source": [
    "# Notes on Sparse Categorical Loss vs. Categorical Loss\n",
    "# Understanding Cross-Entropy Loss\n",
    "\n",
    "At its heart, **cross-entropy** is a concept from information theory that measures how different two probability distributions are. In the context of training a neural network for classification, we use it to measure the \"distance\" between the model's predicted probability distribution and the true probability distribution of the labels. The goal of training is to minimise this distance, effectively making the model's predictions more accurate (Goodfellow et al., 2016).\n",
    "\n",
    "---\n",
    "### Categorical Cross-Entropy (for One-Hot Labels)\n",
    "\n",
    "You use this loss function when your labels are explicitly **one-hot encoded** (e.g., the digit `3` is represented as `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`). The formula for a single sample is:\n",
    "\n",
    "$$L = -\\sum_{i=0}^{C-1} y_i \\log(\\hat{y}_i)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $C$ is the total number of classes (e.g., 10 for MNIST).\n",
    "-   $y_i$ is the ground truth (it is `1` for the correct class and `0` for all others).\n",
    "-   $\\hat{y}_i$ is the model's predicted probability for class $i$.\n",
    "\n",
    "Because the `y` vector is almost all zeros, the summation simplifies to just the negative logarithm of the probability the model assigned to the single correct class. For a label of `3`, the loss simply becomes $L = -\\log(\\hat{y}_3)$.\n",
    "\n",
    "---\n",
    "### Sparse Categorical Cross-Entropy (for Integer Labels)\n",
    "\n",
    "This is a more computationally and memory-efficient version used when your labels are simple **integers** (e.g., `3`). It arrives at the exact same mathematical result but skips the need for the one-hot encoded vector.\n",
    "\n",
    "The formula is a direct implementation of the simplified logic:\n",
    "\n",
    "$$L = -\\log(\\hat{y}_c)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $c$ is the integer representing the correct class (e.g., `c = 3`).\n",
    "-   $\\hat{y}_c$ is the model's predicted probability for that correct class $c$.\n",
    "\n",
    "As Chollet (2021) explains, both formulas compute the exact same value. The choice is purely a practical one based on the format of your labels, not a mathematical one that affects the model's learning.\n",
    "\n",
    "---\n",
    "**References**\n",
    "\n",
    "Chollet, F. (2021). *Deep learning with Python* (2nd ed.). Shelter Island, NY: Manning Publications.\n",
    "\n",
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep learning*. Cambridge, MA: MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7b25e",
   "metadata": {},
   "source": [
    "## Part 1, Task 2: Creating a simple Convolutional Neural Network (CNN)\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the base CNN model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Normalization(input_shape=(28, 28, 1)),\n",
    "        \n",
    "        # --- Convolutional Block 1 ---\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6292216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Set for the Base CNN ---\n",
    "cnn_epochs = 5\n",
    "cnn_batch_size = 64\n",
    "cnn_exp_1_config = {\n",
    "    \"model_name\": \"CNN_Base_Adam\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "cnn_exp_2_config = {\n",
    "    \"model_name\": \"CNN_Base_Adam_Slow_Learn\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "\n",
    "cnn_exp_3_config = {\n",
    "    \"model_name\": \"CNN_SGD\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "\n",
    "cnn_exp_4_config = {\n",
    "    \"model_name\": \"CNN_SGD_Slow_Learn\",\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cnn_experiments = False # A simple flag to control whether we run the CNN experiments or not. This is convenient because CNN experiments take longer to run.\n",
    "# and when we restart the notebook, we might want to just run the MLP experiments first.\n",
    "if run_cnn_experiments:\n",
    "    # --- Run the CNN experiment ---\n",
    "    cnn_histories = []\n",
    "    cnn_history_1 = run_experiment(\n",
    "        model_creation_func=create_cnn_model, \n",
    "        hyperparameters=cnn_exp_1_config,\n",
    "        parent_folder='CNN_Models',\n",
    "        X_train=X_train, \n",
    "        Y_train=Y_train\n",
    "    )\n",
    "    cnn_histories.append(cnn_history_1)\n",
    "\n",
    "    cnn_history_2 = run_experiment(\n",
    "        model_creation_func=create_cnn_model, \n",
    "        hyperparameters=cnn_exp_2_config,\n",
    "        parent_folder='CNN_Models',\n",
    "        X_train=X_train, \n",
    "        Y_train=Y_train\n",
    "    )\n",
    "    cnn_histories.append(cnn_history_2)\n",
    "\n",
    "    cnn_history_3 = run_experiment(\n",
    "        model_creation_func=create_cnn_model, \n",
    "        hyperparameters=cnn_exp_3_config,\n",
    "        parent_folder='CNN_Models',\n",
    "        X_train=X_train, \n",
    "        Y_train=Y_train\n",
    "    )\n",
    "    cnn_histories.append(cnn_history_3)\n",
    "\n",
    "    cnn_history_4 = run_experiment(\n",
    "        model_creation_func=create_cnn_model, \n",
    "        hyperparameters=cnn_exp_4_config,\n",
    "        parent_folder='CNN_Models',\n",
    "        X_train=X_train, \n",
    "        Y_train=Y_train\n",
    "    )\n",
    "    cnn_histories.append(cnn_history_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c387c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Plotting Function ---\n",
    "def plot_training_history(history: History):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy']) # the train accuracy\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{history.model.name} model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss']) # the train loss\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{history.model.name} model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08790f",
   "metadata": {},
   "source": [
    "### Plot the results of every epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_histories(histories):\n",
    "    for history in histories:\n",
    "        plot_training_history(history)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "if run_cnn_experiments:\n",
    "    print_training_histories(mlp_histories)\n",
    "    print_training_histories(cnn_histories)\n",
    "else:\n",
    "    print_training_histories(mlp_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab5e2",
   "metadata": {},
   "source": [
    "## Testing the models on the held-out test set\n",
    "We test the model on the test data, which is data that the model has never seen before. Then we verify the model's real-world accuracy. It is expected that this does not deviate much from the validation sets, because the MNIST dataset contains images that are very clean and simple:\n",
    "- They are small (28 x 28 pixels only).\n",
    "- The digits are centered and normalised in size.\n",
    "- The background is a solid colour with no distracting noise.\n",
    "  \n",
    "Because of this simplicity, the patterns that differentiate one digit from another (e.g., a \"1\" is a vertical line, an \"8\" is two loops) are very strong and easy for our model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af8a5",
   "metadata": {},
   "source": [
    "First we define a function that browser to a folder with saved models, extracts the file with the highest validation accuracy in its name, loads it and tests it with the held-out X_test and Y_test. \n",
    "\n",
    "A function is convenient because we will use it on different models, with different hyperparameters and hence, avoid repetition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_load_and_analyse_best_model(\n",
    "    parent_folder: str, # Changed name for clarity\n",
    "    x_test_data: NDArray[np.float32], \n",
    "    y_test_data: NDArray[np.int_]\n",
    ") -> Tuple[tf.keras.Model | None, float | None, float | None]:\n",
    "    \"\"\"\n",
    "    Recursively searches through all subfolders in a parent directory to find the\n",
    "    single best Keras model, then loads and analyses it.\n",
    "    \"\"\"\n",
    "    best_model_path = None # We will now store the full path directly\n",
    "    best_val_accuracy = -1.0\n",
    "\n",
    "    pattern = re.compile(r\"val_acc-([\\d.]+)\\.keras\")\n",
    "\n",
    "    if not os.path.isdir(parent_folder):\n",
    "        print(f\"Error: Parent directory not found at '{parent_folder}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    # --- NEW: Use os.walk() to search through all subdirectories ---\n",
    "    # os.walk() goes through a directory tree top-down.\n",
    "    for dirpath, _, filenames in os.walk(parent_folder):\n",
    "        for filename in filenames:\n",
    "            match = pattern.search(filename)\n",
    "            if match:\n",
    "                val_accuracy = float(match.group(1))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    # Construct and store the full path to this new best model\n",
    "                    best_model_path = os.path.join(dirpath, filename)\n",
    "    \n",
    "    # The rest of the function works perfectly, we just need to use best_model_path\n",
    "    if best_model_path:\n",
    "        print(f\"Found and loading best model across all experiments: {best_model_path}\")\n",
    "        \n",
    "        loaded_model = tf.keras.models.load_model(best_model_path)\n",
    "        \n",
    "        # --- Print Compiled Hyperparameters ---\n",
    "        print(\"\\n--- Key Hyperparameters ---\")\n",
    "        # Gets the configuration of the model's optimiser.\n",
    "        optimiser_config = loaded_model.optimizer.get_config()\n",
    "        optimiser_name = optimiser_config['name']\n",
    "        learning_rate = optimiser_config['learning_rate']\n",
    "        \n",
    "        # Gets the name of the loss function the model was compiled with.\n",
    "        loss_function = loaded_model.loss\n",
    "        \n",
    "        print(f\"{'Optimiser:':<20} {optimiser_name}\")\n",
    "        print(f\"{'Learning Rate:':<20} {learning_rate}\")\n",
    "        print(f\"{'Loss Function:':<20} {loss_function}\")\n",
    "        \n",
    "        # Prints a summary table of the model's architecture.\n",
    "        print(\"\\n--- Best Model Summary (Architecture) ---\")\n",
    "        loaded_model.summary()\n",
    "\n",
    "        # Evaluates the loaded model's performance on the unseen test data.\n",
    "        print(\"\\n--- Evaluating model performance on the test set ---\")\n",
    "        loss, accuracy = loaded_model.evaluate(x_test_data, y_test_data, verbose=1)\n",
    "        \n",
    "        # Prints the final evaluation results, formatted to 4 decimal places.\n",
    "        print(f\"\\nTest Set Loss: {loss:.4f}\")\n",
    "        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # --- Generate Detailed Performance Analysis ---\n",
    "        print(\"\\n--- Detailed Analysis ---\")\n",
    "        \n",
    "        # Use the model to predict the class for each image in the test set.\n",
    "        y_pred_probabilities = loaded_model.predict(x_test_data)\n",
    "        # The model outputs probabilities; we use np.argmax to find the class with the highest probability.\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "        # Generate and print a text report showing precision, recall, and f1-score for each digit.\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        report = classification_report(y_test_data, y_pred, target_names=[str(i) for i in range(10)])\n",
    "        print(report)\n",
    "\n",
    "        # Generate and plot a confusion matrix to visualise which digits are being confused.\n",
    "        print(\"\\n--- Confusion Matrix ---\")\n",
    "        cm = confusion_matrix(y_test_data, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('Actual Label')\n",
    "        plt.title(f'Confusion Matrix for {loaded_model.name}')\n",
    "        plt.show()\n",
    "        \n",
    "        # Returns the loaded model object and its performance metrics for potential further use.\n",
    "        return loaded_model, accuracy, loss\n",
    "    else:\n",
    "        # If no model files matching the pattern were found, print a message and return nothing.\n",
    "        print(f\"No model files found in any subfolders of '{parent_folder}'.\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24f712",
   "metadata": {},
   "source": [
    "### Testing the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder=\"MLP_Models\"\n",
    "# To capture the output, assign it to variables\n",
    "best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "    parent_folder=model_folder,\n",
    "    x_test_data=X_test,\n",
    "    y_test_data=Y_test\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2e325",
   "metadata": {},
   "source": [
    "### Testing the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_cnn_experiments:\n",
    "    model_folder='CNN_Models'\n",
    "    # To capture the output, assign it to variables\n",
    "    best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "        parent_folder=model_folder,\n",
    "        x_test_data=X_test,\n",
    "        y_test_data=Y_test\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9820dc3",
   "metadata": {},
   "source": [
    "# Future to do's (not part of this assessment)\n",
    "- Implement KerasTuner, to automatically train and test models with a plethora of hyperparamaters, optimisers, loss functions:\n",
    "\n",
    "We first need to install it first: uv pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"This is our hypermodel, which defines the search space.\"\"\"\n",
    "    \n",
    "    model = Sequential(name=\"Tuned_MLP\")\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Normalization())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # --- Define Hyperparameters to Tune ---\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    # Tune the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Add the output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # --- Compile the model inside the function ---\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "--- Set up the Tuner ---\n",
    "### We'll use RandomSearch, which randomly tries combinations.\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # The total number of model variations to test\n",
    "    executions_per_trial=2, # The number of times to train each model variation\n",
    "    directory='tuning_results',\n",
    "    project_name='MNIST_Tuning'\n",
    ")\n",
    "\n",
    "### --- Start the Search ---\n",
    "### This is like model.fit(), but it runs the whole tuning process.\n",
    "tuner.search(X_train, Y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "### --- Get the Best Model ---\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\n--- Best Hyperparameters Found ---\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "print(\"\\n--- Evaluating the Best Model Found by the Tuner ---\")\n",
    "best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428276c",
   "metadata": {},
   "source": [
    "# Testing a new approach (Future to do)\n",
    "### A Base Class for models, with a common interface and allowing for inheriting layers, inheriting behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py\n",
    "# This file serves as a centralised factory for creating our neural network models.\n",
    "# It uses a class-based, inherited structure to keep the codebase organised and extensible.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Normalization, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class BaseNeuralNetwork(Model):\n",
    "    \"\"\"\n",
    "    A base class for all neural networks in this project.\n",
    "    It encapsulates the common input and preprocessing layers that all models will share.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # We call the parent constructor to ensure correct initialisation of the Keras Model.\n",
    "        # **kwargs allows us to pass additional arguments like 'name' when creating subclasses.\n",
    "        super().__init__(**kwargs)\n",
    "        # These layers are common to all models and are defined here once for efficiency.\n",
    "        self.normalization_layer = Normalization(name=\"normalization_layer\")\n",
    "        self.flatten_layer = Flatten(name=\"flatten_layer\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the common preprocessing layers.\n",
    "        \"\"\"\n",
    "        # The input data is passed through the normalisation and flattening layers.\n",
    "        x = self.normalization_layer(inputs)\n",
    "        x = self.flatten_layer(x)\n",
    "        return x\n",
    "\n",
    "class MLPModel(BaseNeuralNetwork):\n",
    "    \"\"\"\n",
    "    A standard Multi-Layer Perceptron (MLP) model.\n",
    "    It inherits the base preprocessing from BaseNeuralNetwork and adds dense layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_units_1: int = 128, num_units_2: int = 256, num_units_3: int = 64, num_classes: int = 10, **kwargs):\n",
    "        # We call the parent constructor and provide a specific name for this model.\n",
    "        super().__init__(name='mlp_model', **kwargs)\n",
    "        # Define the unique dense layers for this specific model architecture.\n",
    "        self.dense_1 = Dense(units=num_units_1, activation='relu', name=\"dense_1\")\n",
    "        self.dense_2 = Dense(units=num_units_2, activation='relu', name=\"dense_2\")\n",
    "        self.dense_3 = Dense(units=num_units_3, activation='relu', name=\"dense_3\")\n",
    "        self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # First, we process the input using the base class's call method.\n",
    "        x = super().call(inputs)\n",
    "        # Then, we pass the output through the MLP-specific layers.\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "class MLP_Wide_Model(BaseNeuralNetwork):\n",
    "    \"\"\"\n",
    "    A wider, shallower MLP model. This is a variation for experimentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_units_1: int = 256, num_units_2: int = 128, num_classes: int = 10, **kwargs):\n",
    "        super().__init__(name='mlp_wide_model', **kwargs)\n",
    "        # This model has a different configuration of dense layers.\n",
    "        self.dense_1 = Dense(units=num_units_1, activation='relu', name=\"dense_1\")\n",
    "        self.dense_2 = Dense(units=num_units_2, activation='relu', name=\"dense_2\")\n",
    "        self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = super().call(inputs)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "class SimpleCNN(BaseNeuralNetwork):\n",
    "    \"\"\"\n",
    "    A simple Convolutional Neural Network (CNN) model for image classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 10, **kwargs):\n",
    "        super().__init__(name='simple_cnn', **kwargs)\n",
    "        # The convolutional and pooling layers are unique to CNNs.\n",
    "        self.conv1 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', name=\"conv1\")\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool1\")\n",
    "        self.conv2 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv2\")\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool2\")\n",
    "        self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # We start by using the base class's normalisation.\n",
    "        x = self.normalization_layer(inputs)\n",
    "        \n",
    "        # Then, we pass the output through the CNN-specific layers.\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # The flatten layer from the base class is still applied before the output layer.\n",
    "        x = self.flatten_layer(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "class DeepCNN(BaseNeuralNetwork):\n",
    "    \"\"\"\n",
    "    A deeper CNN model with more layers for greater representational capacity.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 10, **kwargs):\n",
    "        super().__init__(name='deep_cnn', **kwargs)\n",
    "        # This model has a more complex arrangement of convolutional layers.\n",
    "        self.conv1 = Conv2D(32, (3, 3), activation='relu')\n",
    "        self.conv2 = Conv2D(32, (3, 3), activation='relu')\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = Conv2D(64, (3, 3), activation='relu')\n",
    "        self.conv4 = Conv2D(64, (3, 3), activation='relu')\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.output_layer = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.normalization_layer(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "def create_model_from_class(model_class: type, input_shape, **kwargs):\n",
    "    \"\"\"\n",
    "    A helper function to instantiate a model class with a defined input shape.\n",
    "    It automatically builds the model for you.\n",
    "    \"\"\"\n",
    "    model_instance = model_class(**kwargs)\n",
    "    # The build method ensures that the model's layers are initialised with the correct input shape.\n",
    "    model_instance.build(input_shape=(None,) + input_shape)\n",
    "    return model_instance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
