{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a43b04",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85a5a6",
   "metadata": {},
   "source": [
    "### Import relevant dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbc1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the MNIST dataset from Keras, a classic collection of 70,000 grayscale images of handwritten digits (0-9).\n",
    "from keras.datasets import mnist \n",
    "\n",
    "# Imports TensorFlow, the core open-source library from Google for building and training machine learning models. We use the alias 'tf' by convention.\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import TensorShape \n",
    "\n",
    "from visualkeras import SpacingDummyLayer # Added for better text spacing\n",
    "\n",
    "# Imports the Adam optimiser. An optimiser is an algorithm that adjusts the model's internal parameters (weights) to minimise the error, and Adam is a popular, efficient choice.\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# Imports specific performance metrics. Metrics are used to evaluate how well the model is performing.\n",
    "# Precision: Measures the accuracy of positive predictions.\n",
    "# Recall: Measures the model's ability to find all the actual positive instances.\n",
    "# Accuracy: Measures the overall fraction of correct predictions.\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "\n",
    "# Imports the History callback object. A 'callback' is a function that can be executed at different stages of training. The History object automatically records the metrics and loss values from each epoch.\n",
    "from tensorflow.python.keras.callbacks import History\n",
    "\n",
    "# Imports the ModelCheckpoint callback. This callback saves the model to a file during training, typically only when its performance on a validation metric improves.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Imports the Pandas library, a powerful tool for data manipulation and analysis. It's mainly used for working with structured data in tables called DataFrames. 'pd' is the standard alias.\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the Sequential model type from Keras. This is the simplest way to build a model, by creating a linear stack of layers.\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# Imports different types of layers, which are the fundamental building blocks of a neural network.\n",
    "# Dense: A standard, fully-connected layer where each neuron is connected to every neuron in the previous layer.\n",
    "# Input: A special layer used to define the shape and data type of the model's input.\n",
    "# Flatten: A layer that transforms a multi-dimensional input (like a 2D image) into a one-dimensional vector.\n",
    "# Normalization: A preprocessing layer that scales input data to a standard range (e.g., mean of 0, standard deviation of 1), which helps the model train faster. \n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Normalization, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Imports a utility function from scikit-learn, a popular library for traditional machine learning. train_test_split is used to split a single dataset into separate training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports the pyplot interface from Matplotlib, which is the most widely used library for creating plots and visualisations in Python. 'plt' is the standard alias.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports the NumPy library, which is the foundation for numerical computing in Python. It provides support for large, multi-dimensional arrays and a wide range of mathematical functions. 'np' is the standard alias.\n",
    "import numpy as np\n",
    "\n",
    "# Imports a data scaling tool from scikit-learn. MinMaxScaler scales all data features to a specific range, usually 0 to 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Imports tools for 'type hinting' from Python's typing module. Type hints make code more readable and can be used by external tools to check for errors.\n",
    "# Tuple: Used to hint that a variable or function return is a tuple (an ordered, immutable collection of elements).\n",
    "from typing import Tuple\n",
    "\n",
    "# Imports a specific type hint from NumPy's typing module.\n",
    "# NDArray: Used to hint that a variable is a NumPy n-dimensional array, which is more descriptive than a generic type.\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Imports the 'os' module. This library provides a way for Python to interact with the computer's underlying operating system.\n",
    "# We use it for tasks like reading file names from a folder (os.listdir()) and constructing file paths that work correctly on any system, like Windows, Mac, or Linux (os.path.join()).\n",
    "import os \n",
    "\n",
    "# Imports the 're' module, which stands for Regular Expression. This is Python's library for advanced pattern matching in strings.\n",
    "# We use it to find and extract specific pieces of text from a string, like pulling the accuracy score out of a complex filename (e.g., finding '0.9935' in 'model_acc-0.9935.keras').\n",
    "import re\n",
    "\n",
    "# The seaborn dependency is used for plotting confusion matrices. \n",
    "import seaborn as sns\n",
    "\n",
    "# Wandb allows us to log the results of our experiments online at the WandB platform. This platform can be used to visualise plots of our models'\n",
    "# performance (accuracy, loss) per model, or for all models at once. Additionally, this platform keeps track of the models' architecture and hyperparameters used in the trainig process. \n",
    "import wandb\n",
    "\n",
    "# This import allows us to log the metrics generated by our models (Keras)\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "import datetime\n",
    "\n",
    "import visualkeras\n",
    "\n",
    "import warnings\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import ImageFont\n",
    "\n",
    "from IPython.display import display # Needed to show plots inside a function\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ce86f",
   "metadata": {},
   "source": [
    "# Import the dataset\n",
    "\n",
    "### Define the training set features (X_train) and target variable (Y_train) as well as the test set features (X_test_) and target variable (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b32fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape for X_train for CNN's: (60000, 28, 28, 1)\n",
      "New shape for X_test for CNN's: (10000, 28, 28, 1)\n",
      "Shape of X_train:\t (60000, 28, 28, 1)\n",
      "Shape of X_test:\t (10000, 28, 28, 1)\n",
      "Shape of Y_train:\t (60000,)\n",
      "Shape of Y_test:\t (10000,)\n",
      "X_train data type: float32\n",
      "X_test data type: float32\n",
      "Y_train data type: uint8\n",
      "Y_test data type: uint8\n",
      "\n",
      "X_train data 567-th element (a 28x28 pixel image):\n",
      " [[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 198. 254. 254. 162. 161. 161. 161. 162.  78.  13.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 253. 253. 254. 253. 253. 253. 254. 253. 234. 163.  68.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  26. 181. 253. 230. 230. 154. 205. 230. 242. 253. 253. 241.  95.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  15. 128.   0.   0.   0.   0.   0.  38. 119. 253. 254. 115.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  83. 254. 255. 115.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   9. 174. 253. 216.  19.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 164. 253. 244. 101.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 119. 247. 253. 128.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  85. 254. 254. 146.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81. 222. 254. 210.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 245. 253. 214.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  26. 239. 253. 219.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 254. 254. 214.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   9.  97. 247. 254. 227.  46.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   7.  99. 253. 253. 214.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0. 104. 253. 253. 219.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  85. 255. 254. 146.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 106. 247. 241. 139.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 157. 253. 142.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 174. 219.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "\n",
      "And its corresponding label:\t 7\n",
      "\n",
      "--- Train Dataset Distribution ---\n",
      "Digits:\t\t\t [0 1 2 3 4 5 6 7 8 9]\n",
      "Count per digit:\t [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "Average sample size:\t 6000.00\n",
      "Maximum sample size:\t 6742\n",
      "Minimum sample size:\t 5421\n",
      "\n",
      "--- Test Dataset Distribution ---\n",
      "Digits:\t\t\t [0 1 2 3 4 5 6 7 8 9]\n",
      "Count per digit:\t [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n",
      "Average sample size:\t 1000.00\n",
      "Maximum sample size:\t 1135\n",
      "Minimum sample size:\t 892\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MNIST dataset, which is a large database of handwritten digits.\n",
    "# The function returns two tuples: one for training data and one for testing data.\n",
    "# Recalling, a Tuple is a collection of objects that are ordered and immutable.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# First we convert the data to float32, which helps with numerical stability. A float32 provides sufficient precision, while also being memory efficient.\n",
    "# Most modern CPU's and GPU's are optimized for float32 operations, making computations faster.\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# Then we convert the training data to have a channel dimension, which is required for CNNs.\n",
    "X_train = X_train[..., tf.newaxis] # Add the channel dimension\n",
    "X_test = X_test[..., tf.newaxis] # Add the channel dimension\n",
    "print(f\"New shape for X_train for CNN's: {X_train.shape}\")\n",
    "print(f\"New shape for X_test for CNN's: {X_test.shape}\")\n",
    "\n",
    "# Declare the types of the loaded data for clarity.\n",
    "X_train: NDArray[np.float32]\n",
    "Y_train: NDArray[np.uint8]\n",
    "X_test: NDArray[np.float32]\n",
    "Y_test: NDArray[np.uint8]\n",
    "\n",
    "# We set the line width to a large value to avoid line breaks when printing the array.\n",
    "with np.printoptions(linewidth=10000):\n",
    "    # Print the shapes of the datasets to understand their dimensions.\n",
    "    print(\"Shape of X_train:\\t\", X_train.shape)\n",
    "    print(\"Shape of X_test:\\t\", X_test.shape)\n",
    "    print(\"Shape of Y_train:\\t\", Y_train.shape)\n",
    "    print(\"Shape of Y_test:\\t\", Y_test.shape)\n",
    "    print(f\"X_train data type: {X_train.dtype}\")\n",
    "    print(f\"X_test data type: {X_test.dtype}\")\n",
    "    print(f\"Y_train data type: {Y_train.dtype}\")\n",
    "    print(f\"Y_test data type: {Y_test.dtype}\")\n",
    "\n",
    "    # Inspect a single data sample to see what it looks like.\n",
    "    n: int = 567\n",
    "    print(f\"\\nX_train data {n}-th element (a 28x28 pixel image):\\n\", np.squeeze(X_train[n]))\n",
    "    print(\"\\nAnd its corresponding label:\\t\", Y_train[n])\n",
    "\n",
    "    # TODO: For using this data in a neural network,\n",
    "    # Tensorflow/Keras expects the input data to be in a 1D or 2D array format where each row represents a single sample and each column represents a feature. The general format for the input shape is: (batch_size, feature_1, feature_2, ...)\n",
    "    # However, we can use the tf.keras.layers.Flatten layer as the first layer in our sequential model.\n",
    "    # This layer automatically flattens the input shape without the need for manual reshaping of our data.\n",
    "    # For a Dense (fully connected) network: We must flatten each 28x28 image into a single 1D array of 784 pixels. The input shape for the first layer of our model would then be (None, 784), where None represents a variable batch size.\n",
    "    # For a Convolutional Neural Network (CNN): We must add a channel dimension. Since the images are grayscale, there is only one channel. We would reshape the data to (number_of_images, 28, 28, 1). The input shape for the first layer (typically a Conv2D layer) would be (28, 28, 1). The batch size is handled automatically by Keras.\n",
    "    # Scaling can also be performd in the model using a tf.keras.layers.Rescaling or keras.layers.Normalization layer as the first layer in our sequential model.\n",
    "    # The advantage of using these layers is that they integrate seamlessly into the model architecture, ensuring that the data is preprocessed consistently during both training and inference.\n",
    "    # This approach also simplifies the code by reducing the need for separate preprocessing steps outside the model definition.\n",
    "    # And, it ensures that inference data is processed in the same way as training data, which is crucial for maintaining model performance.\n",
    "\n",
    "    # Analyze the distribution of the digits in the training set.\n",
    "    # `np.unique` finds the unique digit labels and `return_counts=True` counts their occurrences.\n",
    "    dataset_train_distribution: Tuple[np.ndarray, np.ndarray] = np.unique(Y_train, return_counts=True)\n",
    "    digits_train: np.ndarray = dataset_train_distribution[0]\n",
    "    counts_train: np.ndarray = dataset_train_distribution[1]\n",
    "    \n",
    "    print(\"\\n--- Train Dataset Distribution ---\")\n",
    "    print(\"Digits:\\t\\t\\t\", digits_train)\n",
    "    print(\"Count per digit:\\t\", counts_train)\n",
    "    \n",
    "    # Calculate basic statistics on the distribution.\n",
    "    avg: float = np.mean(counts_train)\n",
    "    print(f\"Average sample size:\\t {avg:.2f}\")\n",
    "    \n",
    "    max_count_train: np.int64 = np.max(counts_train)\n",
    "    min_count_train: np.int64 = np.min(counts_train)\n",
    "    print(f\"Maximum sample size:\\t {max_count_train}\")\n",
    "    print(f\"Minimum sample size:\\t {min_count_train}\")\n",
    "\n",
    "\n",
    "    dataset_test_distribution: Tuple[np.ndarray, np.ndarray] = np.unique(Y_test, return_counts=True)\n",
    "    digits_test: np.ndarray = dataset_test_distribution[0]\n",
    "    counts_test: np.ndarray = dataset_test_distribution[1]\n",
    "    \n",
    "    print(\"\\n--- Test Dataset Distribution ---\")\n",
    "    print(\"Digits:\\t\\t\\t\", digits_test)\n",
    "    print(\"Count per digit:\\t\", counts_test)\n",
    "    \n",
    "    # Calculate basic statistics on the distribution.\n",
    "    avg: float = np.mean(counts_test)\n",
    "    print(f\"Average sample size:\\t {avg:.2f}\")\n",
    "    \n",
    "    max_count_test: np.int64 = np.max(counts_test)\n",
    "    min_count_test: np.int64 = np.min(counts_test)\n",
    "    print(f\"Maximum sample size:\\t {max_count_test}\")\n",
    "    print(f\"Minimum sample size:\\t {min_count_test}\")\n",
    "\n",
    "# Create a bar chart from the counts and digits to visualize the distribution.\n",
    "plt.bar(digits_train, counts_train, color='blue', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for clarity.\n",
    "plt.title('Count of Each Digit in Training Set')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Set x-ticks to be at the center of each bar and label them with the digit.\n",
    "# Minor ticks are used here to place the labels directly under the bars.\n",
    "# Ticks specify the positions on the x-axis where the labels should be placed.\n",
    "# By setting ticks=digits_train, we ensure that each digit (0-9) is labeled correctly under its corresponding bar.\n",
    "plt.xticks(ticks=digits_train, minor=True, labels=digits_train)\n",
    "\n",
    "# Add a grid for better readability.\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()\n",
    "\n",
    "# And the same bar chart for the test set.\n",
    "\n",
    "# Create a bar chart from the counts and digits to visualize the distribution.\n",
    "plt.bar(digits_test, counts_test, color='red', edgecolor='black')\n",
    "\n",
    "# Set the title and labels for clarity.\n",
    "plt.title('Count of Each Digit in Test Set')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Set x-ticks to be at the center of each bar and label them with the digit.\n",
    "plt.xticks(ticks=digits_test, minor=True, labels=digits_test)\n",
    "\n",
    "# Add a grid for better readability.\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d4acf",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "The content and size of the training and testing datasets align with the description on the Kaggle MNIST dataset page, Hojjat, F. (2017). MNIST: The Most Famous Dataset in the World. Kaggle. Retrieved August 28, 2025, from https://www.kaggle.com/datasets/hojjatk/mnist-dataset. The plot of digit distribution shows a fairly homogeneous representation across all classes (digits 0 through 9). While the digit '1' is slightly oversampled and the digit '5' is slightly undersampled, the class imbalance is not significant enough to warrant further action for this assessment.\n",
    "\n",
    "In a scenario where the distribution were to be significantly imbalanced and we needed to make it more homogeneous, we would use a technique called **resampling**. Resampling involves adjusting the distribution of the training data to be more balanced. There are two primary types:\n",
    "\n",
    "- **Oversampling** involves duplicating samples from the underrepresented classes to increase their frequency.\n",
    "\n",
    "- **Undersampling** involves removing samples from the overrepresented classes to reduce their frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5568184",
   "metadata": {},
   "source": [
    "## Part 1, Task 1: Creating a simple Multilayer Perceptron (MLP) neural network\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b401b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set Seeds for Reproducibility ---\n",
    "\n",
    "# This sets the global random seed for all TensorFlow operations.\n",
    "# It ensures that things like model weight initialisation are the same every time.\n",
    "# `tf.random.set_seed()` is the modern way to do this in TensorFlow 2.\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# This sets the random seed for all NumPy operations.\n",
    "# This is important if we are creating our data using NumPy or using any\n",
    "# NumPy functions that involve randomness.\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765eac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Task 1**\n",
    "\n",
    "# Build a neural network without convolutional layers to do the classification task (hint: you will need the use of dense layers). \n",
    "# Then you can change the model structure (i.e. number of dense layers, number of neurons in dense layers or activation functions) to be able to improve network performance.\n",
    "\n",
    "def create_mlp_model_base() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=32, activation='relu'), # Relu is the goto activation function. We could also use LeakyRelu, tanh, sigmoid, etc.\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name = \"Base_MLP_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1216af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model_2() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=64, activation='relu'), # Relu is the goto activation function. We could also use LeakyRelu, tanh, sigmoid, etc.\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name = \"Base_MLP_Model_2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361f3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our first \"base\" model we created. Repeated here, because it yielded very good accuracies on both validate and test data, as well as loss. \n",
    "def create_mlp_model_3() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'), # Relu is the goto activation function. We could also use LeakyRelu, \n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name = \"Base_MLP_Model_3\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954def66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model_wide() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=512, activation='relu'),\n",
    "        Dense(units=1024, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name = \"Wide_MLP_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6283beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model_deep() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the (base) MLP model architecture.\n",
    "    \"\"\"\n",
    "    # Note: we can change the model architecture here. However, it is more prudent to save the model parameters first, and then change it. \n",
    "    model = Sequential([\n",
    "        # We use the implicit input_shape here for a cleaner look.\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name=\"Deep_MLP_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a924894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All MLP models:\n",
    "mlp_model_functions = [\n",
    "create_mlp_model_base,\n",
    "create_mlp_model_2,\n",
    "create_mlp_model_3,\n",
    "create_mlp_model_wide,\n",
    "create_mlp_model_deep,\n",
    "]\n",
    "\n",
    "# # Only a single model:\n",
    "# mlp_model_functions = [\n",
    "# create_mlp_model_3,\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8c4cf",
   "metadata": {},
   "source": [
    "### Define the training loop\n",
    "\n",
    "This training loop will be called for both the MLP as well as the CNN models. This function is convenient, as it only needs to be defined once, and we can pass in different models, hyperparameter sets, and train data to our liking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_creation_func, hyperparameters, parent_folder, X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Runs a full training experiment for a given model architecture and hyperparameter set.\n",
    "    \"\"\"\n",
    "    # Create the model instance first.\n",
    "    model = model_creation_func()\n",
    "\n",
    "    # Set default hyperparameters in case they are not provided in the hyperparameters dictionary.\n",
    "    default_lr = 0.001\n",
    "    default_optimiser = 'adam'\n",
    "    default_batch_size = 64\n",
    "    default_epochs = 10\n",
    "    if model.name is None or model.name == \"\":\n",
    "        model.name = model_creation_func.__name__\n",
    "\n",
    "    # --- Adapt the Normalisation Layer ---\n",
    "    print(\"\\nAdapting the normalisation layer...\")\n",
    "    # The adapt method is now called here, before the model is compiled or trained.\n",
    "    model.layers[0].adapt(X_train)\n",
    "    print(\"Adaptation complete.\\n\")\n",
    "\n",
    "    print(f\"\\n--- Starting Experiment: {model.name} ---\")\n",
    "\n",
    "    # We can print a summary of the model's architecture to see the layers and parameter counts.\n",
    "    print(\"\\n--- Model Architecture ---\")\n",
    "    model.summary()\n",
    "    # Generate the model's diagram as an image file\n",
    "    # plot_model(model, to_file=f'{model.name}_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # And we can also print the hyperparameters of the model.\n",
    "    print(\"\\n--- Hyperparameters ---\")\n",
    "    for key, value in hyperparameters.items():\n",
    "        print(f\"{key:<20}: {value}\")\n",
    "\n",
    "    # --- Initialise WandB Run and Callbacks ---\n",
    "    # The callbacks and WandB run are configured AFTER the model is fully built and adapted.\n",
    "    # This is important because the WandBMetricsLogger callback inspects the model to log its architecture and parameters.\n",
    "    # The run_name includes the model name, learning rate, batch size, and a timestamp for uniqueness.\n",
    "    run_name = f\"{model.name}-lr_{hyperparameters.get('learning_rate', default_lr)}-bs_{hyperparameters.get('batch_size', default_batch_size)}-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    # local_log_dir = os.path.join(os.getcwd(), \"wandb\", run_name)\n",
    "    local_log_dir = os.path.join(os.getcwd(), \"wandb\")\n",
    "    os.makedirs(local_log_dir, exist_ok=True)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"CSE5ML-Assessment2\",\n",
    "        name=run_name,\n",
    "        config=hyperparameters,\n",
    "        dir=local_log_dir,\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(parent_folder, \"logs\", model.name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    wandb_metrics_logger = WandbMetricsLogger()\n",
    "\n",
    "    # --- Configure the Optimiser ---\n",
    "    optimiser_name = hyperparameters.get('optimiser', default_optimiser).lower() # Default to 'adam' if not specified\n",
    "    learning_rate = hyperparameters.get('learning_rate', default_lr) # Default to 0.001 if not specified\n",
    "\n",
    "    if optimiser_name == 'adam':\n",
    "        optimiser = Adam(learning_rate=learning_rate) # We use the Adam Object rather than the string 'adam' to be explicit. The difference is that we can see the learning rate in the model summary.\n",
    "    elif optimiser_name == 'sgd':\n",
    "        optimiser = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimiser = optimiser_name\n",
    "\n",
    "    # --- Configure the ModelCheckpoint Callback ---\n",
    "    model_specific_folder = os.path.join(parent_folder, model.name) # This creates a sub-folder for each model type under the parent folder.\n",
    "    os.makedirs(model_specific_folder, exist_ok=True) # exist_ok=True avoids an error if the folder already exists.\n",
    "    filepath = os.path.join(model_specific_folder, 'best_model_epoch-{epoch:02d}_val_acc-{val_accuracy:.4f}.keras') #The filepath now includes the model name, the best epoch and validation accuracy as a sub-folder.\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1 # Only print messages when the model improves\n",
    "    )\n",
    "\n",
    "    # Configure the EarlyStopping callback\n",
    "    # - monitor='val_loss': Watch the validation loss.\n",
    "    # - patience=3: Stop training if val_loss doesn't improve for 3 consecutive epochs.\n",
    "    # - restore_best_weights=True: Restore model weights from the epoch with the best val_loss.\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy', # we track the loss, because this tells us: how certain the model is about its predictions, rather than just saying whether it was right or wrong. E.g.: 51% confindence the digit is a 2. So accuracy = 100% - but it's not very sure.\n",
    "        patience=10, # We use a patience of 10 epochs to allow the model more time to improve, especially with a lower learning rate.\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Compile the Model ---\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss=hyperparameters.get('loss_function', 'sparse_categorical_crossentropy'),\n",
    "        metrics=['accuracy'] # For multi-class classification, 'accuracy' is appropriate. However, we could also add Precision() and Recall() here if needed.\n",
    "    )\n",
    "\n",
    "    # --- Train the Model ---\n",
    "    # history is a History object that contains details about the training process, including the loss and accuracy for each epoch.\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=hyperparameters.get('epochs', default_epochs),\n",
    "        batch_size=hyperparameters.get('batch_size', default_batch_size),\n",
    "        validation_split=0.1, # Setting the validation set to 10% of the training set. \n",
    "        callbacks=[checkpoint, wandb_metrics_logger, tensorboard_callback, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    # Attach the hyperparameter dictionary to the history object itself, so it is directly related to the history.\n",
    "    history.hyperparameters = hyperparameters\n",
    "\n",
    "    # The history.history dictionary contains a list of validation accuracies for each epoch.\n",
    "    val_accuracies = history.history['val_accuracy']\n",
    "    best_validation_accuracy = max(val_accuracies)\n",
    "    best_epoch = val_accuracies.index(best_validation_accuracy) + 1\n",
    "    associated_train_acc = history.history['accuracy'][best_epoch - 1]\n",
    "\n",
    "    print(\"\\n--- Peak Performance Summary ---\")\n",
    "    print(f\"{'Best validation accuracy:':<35} {best_validation_accuracy:.4f}\")\n",
    "    print(f\"{'Associated training accuracy:':<35} {associated_train_acc:.4f}\")\n",
    "    print(f\"{'Occurred at epoch:':<35} {best_epoch}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c83321",
   "metadata": {},
   "source": [
    "### Define sets of hyperparameters\n",
    "\n",
    "The cell below allow us to set a plethora of hyperparameters, such as the learning rate, batch_size, but also the optimiser and the number of epochs the training loop is run for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Sets ---\n",
    "# Part 1 Task 3 only requires one experiment with an MLP, so we will just define one hyperparameter set for the MLP here.\n",
    "mlp_epochs = 100\n",
    "mlp_batch_size = 64\n",
    "# Experiment 1: Our baseline run\n",
    "# We choose SGD as our optimiser because it is expected that the loss landscape of our simple MLP model is largely convex. \n",
    "mlp_exp_1_config = {\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001, # The optimal, or at least a satisfactory LR will have to be identified by experimenting. We start with LR = 0.01. This does not lead to convergence of Loss and Accuracy. So LR=0.001 is used. \n",
    "    \"epochs\": mlp_epochs,\n",
    "    \"batch_size\": mlp_batch_size\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# # Experiment 2: Same as the MLP_Baseline but with a lower learning rate\n",
    "# mlp_exp_2_config = {\n",
    "#     \"optimiser\": \"Adam\",\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"epochs\": mlp_epochs,\n",
    "#     \"batch_size\": mlp_batch_size,\n",
    "# }\n",
    "\n",
    "# # Experiment 3: Same as the MLP_Baseline but with a different optimizer (SGD)\n",
    "# mlp_exp_3_config = {\n",
    "#     \"optimiser\": \"SGD\",\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"epochs\": mlp_epochs,\n",
    "#     \"batch_size\": mlp_batch_size,\n",
    "# }\n",
    "\n",
    "# # Experiment 4: Same as the MLP_Baseline but with a different optimizer (SGD) and a lower learning rate\n",
    "# mlp_exp_4_config = {\n",
    "#     \"optimiser\": \"SGD\",\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"epochs\": mlp_epochs,\n",
    "#     \"batch_size\": mlp_batch_size,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67af808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the full list of models ---\n",
    "run_mlp_experiments = False\n",
    "\n",
    "if run_mlp_experiments:\n",
    "    mlp_histories = []\n",
    "    for mlp_model_function in mlp_model_functions:\n",
    "        mlp_history = run_experiment(\n",
    "            model_creation_func=mlp_model_function, \n",
    "            # But use only one set of hyperparameters for now.\n",
    "            hyperparameters=mlp_exp_1_config, \n",
    "            parent_folder='MLP_Models',\n",
    "            X_train=X_train,\n",
    "            Y_train=Y_train,\n",
    "        )\n",
    "        mlp_histories.append(mlp_history)\n",
    "\n",
    "# # --- To run the second experiment, we just call it again with a different config (hyper parameter set) :-)\n",
    "# --- We first  test different model architectures before running more experiments with different hyperparameters (Part 1 Task 1 & 2). ---\n",
    "# --- THen we test the best performing model of Part 1 Task 1& 2 with different hyperparameters. ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94357c",
   "metadata": {},
   "source": [
    "# Notes on Sparse Categorical Loss vs. Categorical Loss\n",
    "# Understanding Cross-Entropy Loss\n",
    "\n",
    "At its heart, **cross-entropy** is a concept from information theory that measures how different two probability distributions are. In the context of training a neural network for classification, we use it to measure the \"distance\" between the model's predicted probability distribution and the true probability distribution of the labels. The goal of training is to minimise this distance, effectively making the model's predictions more accurate (Goodfellow et al., 2016).\n",
    "\n",
    "---\n",
    "### Categorical Cross-Entropy (for One-Hot Labels)\n",
    "\n",
    "You use this loss function when your labels are explicitly **one-hot encoded** (e.g., the digit `3` is represented as `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`). The formula for a single sample is:\n",
    "\n",
    "$$L = -\\sum_{i=0}^{C-1} y_i \\log(\\hat{y}_i)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $C$ is the total number of classes (e.g., 10 for MNIST).\n",
    "-   $y_i$ is the ground truth (it is `1` for the correct class and `0` for all others).\n",
    "-   $\\hat{y}_i$ is the model's predicted probability for class $i$.\n",
    "\n",
    "Because the `y` vector is almost all zeros, the summation simplifies to just the negative logarithm of the probability the model assigned to the single correct class. For a label of `3`, the loss simply becomes $L = -\\log(\\hat{y}_3)$.\n",
    "\n",
    "---\n",
    "### Sparse Categorical Cross-Entropy (for Integer Labels)\n",
    "\n",
    "This is a more computationally and memory-efficient version used when your labels are simple **integers** (e.g., `3`). It arrives at the exact same mathematical result but skips the need for the one-hot encoded vector.\n",
    "\n",
    "The formula is a direct implementation of the simplified logic:\n",
    "\n",
    "$$L = -\\log(\\hat{y}_c)$$\n",
    "\n",
    "-   $L$ is the final loss value for the sample.\n",
    "-   $c$ is the integer representing the correct class (e.g., `c = 3`).\n",
    "-   $\\hat{y}_c$ is the model's predicted probability for that correct class $c$.\n",
    "\n",
    "As Chollet (2021) explains, both formulas compute the exact same value. The choice is purely a practical one based on the format of your labels, not a mathematical one that affects the model's learning.\n",
    "\n",
    "---\n",
    "**References**\n",
    "\n",
    "Chollet, F. (2021). *Deep learning with Python* (2nd ed.). Shelter Island, NY: Manning Publications.\n",
    "\n",
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep learning*. Cambridge, MA: MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7b25e",
   "metadata": {},
   "source": [
    "## Part 1, Task 2: Creating a simple Convolutional Neural Network (CNN)\n",
    "\n",
    "The code below defines our base model.\n",
    "\n",
    "To experiment with different architectures or tune its hyperparameters, we simply copy this entire cell and make our changes.\n",
    "\n",
    "We need to make sure to give each new model a unique name. This ensures that when the ModelCheckpoint callback saves the best-performing version during training, the filename will be clear and identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d24564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Task 2**\n",
    "\n",
    "# Build a neural network with the use of convolutional layers (you can decide other layer types you want to include in your network). \n",
    "# Then you can change the number of convolutional layers and the number of filters or activation functions in the convolutional layers to be able to improve network performance.\n",
    "\n",
    "def create_cnn_model_base() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines the base CNN model architecture with Dropout for regularization.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        \n",
    "        # --- Convolutional Block 1 ---\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        SpacingDummyLayer(spacing=15),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        Flatten(),\n",
    "        # Dropout(0.5),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name=\"Base_CNN\")\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5954ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second CNN base model with the same architecture, but a dropout in the classification head.\n",
    "def create_cnn_model_base_dropout() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns the base CNN model architecture with dropout in the classification head.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "            \n",
    "        # --- Convolutional Block 1 ---\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name=\"CNN_with_Dropout\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1879ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wide CNN \n",
    "def create_cnn_model_wide() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns a wide CNN model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        \n",
    "        # --- Convolutional Block 1 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name=\"Wide_CNN_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec63191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model_deep() -> Sequential:\n",
    "    \"\"\"\n",
    "    Defines and returns a deep CNN model architecture with padding to preserve dimensions.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Normalization(),\n",
    "        \n",
    "        # --- Convolutional Block 1 ---\n",
    "        # Add padding='same' to all Conv2D layers, so we preserve the spatial dimensions. If we don't do this, the image shrinks too quickly.\n",
    "        # and no meaningful features can be extracted.\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)), # This is where the shrinking now happens (28x28 -> 14x14)\n",
    "\n",
    "        # --- Convolutional Block 2 ---\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)), # Second shrink (14x14 -> 7x7)\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        # The input to Flatten is now a healthy 7x7x64=3,136 full of rich features.\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dense(units=10, activation='softmax')\n",
    "    ], name=\"Deep_CNN_Model_Padded\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12d18c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_functions = [\n",
    "create_cnn_model_base,\n",
    "create_cnn_model_base_dropout,\n",
    "create_cnn_model_wide,\n",
    "# create_cnn_model_deep, # We teain the deep network separately with a much lower LR. We have observed that this model performs no better than a random guess (i.e. 10% val. accuracy)\n",
    "# Almost certainly this has to do with the LR, the model can't get to the valleys of the loss landscape, as it overshoots. \n",
    "# Future to do: Find a way to reduce the loss landscape to 3D, or 2D dimension, and show the parth the Optimiser takes, to be able to demonstrate the effect of the LR. \n",
    "]\n",
    "\n",
    "\n",
    "# cnn_model_functions = [\n",
    "# create_cnn_model_deep,\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a722801",
   "metadata": {},
   "source": [
    "# Plotting all model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c7eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_callable(layer_index, layer):\n",
    "#     above = bool(layer_index % 2)\n",
    "\n",
    "#     # --- MORE ROBUST SHAPE HANDLING ---\n",
    "#     # Try to get the shape from the more modern '.output.shape' attribute\n",
    "#     try:\n",
    "#         shape = layer.output.shape\n",
    "#     except AttributeError:\n",
    "#         # Fallback to '.output_shape' for layers like Input\n",
    "#         try:\n",
    "#             shape = layer.output_shape\n",
    "\n",
    "#         except AttributeError:\n",
    "#             # If all else fails, we can't determine the shape\n",
    "#             return f\"{layer.name}\\n(Shape N/A)\", above\n",
    "\n",
    "#     # Handle nested lists of shapes (which can come from Input layers)\n",
    "#     if isinstance(shape, list):\n",
    "#         shape = shape[0]\n",
    "\n",
    "#     # Convert TensorShape to list, otherwise, ensure it's a list\n",
    "#     if isinstance(shape, TensorShape):\n",
    "#         output_shape = shape.as_list()\n",
    "#     else:\n",
    "#         output_shape = list(shape)\n",
    "    \n",
    "#     # Remove the 'None' batch dimension for cleaner plotting\n",
    "#     output_shape = [dim for dim in output_shape if dim is not None]\n",
    "#     # --- END OF FIX ---\n",
    "\n",
    "#     # Create a string representation of the output shape\n",
    "#     output_shape_txt = \"\"\n",
    "#     for ii, dim in enumerate(output_shape):\n",
    "#         output_shape_txt += str(dim)\n",
    "#         if ii < len(output_shape) - 2:\n",
    "#             output_shape_txt += \"x\"\n",
    "#         if ii == len(output_shape) - 2:\n",
    "#             output_shape_txt += \"\\n\"\n",
    "\n",
    "#     output_shape_txt += f\"\\n{layer.name}\"\n",
    "\n",
    "#     return output_shape_txt, above\n",
    "\n",
    "\n",
    "def text_callable(layer_index, layer):\n",
    "    above = bool(layer_index % 2)\n",
    "    try:\n",
    "        shape = layer.output.shape\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            shape = layer.output_shape\n",
    "        except AttributeError:\n",
    "            return f\"{layer.name}\\n(Shape N/A)\", above\n",
    "    if isinstance(shape, list):\n",
    "        shape = shape[0]\n",
    "    if isinstance(shape, TensorShape):\n",
    "        output_shape = shape.as_list()\n",
    "    else:\n",
    "        output_shape = list(shape)\n",
    "    output_shape = [dim for dim in output_shape if dim is not None]\n",
    "    output_shape_txt = \"\"\n",
    "    for ii, dim in enumerate(output_shape):\n",
    "        output_shape_txt += str(dim)\n",
    "        if ii < len(output_shape) - 2:\n",
    "            output_shape_txt += \"x\"\n",
    "        if ii == len(output_shape) - 2:\n",
    "            output_shape_txt += \"\\n\"\n",
    "    output_shape_txt += f\"\\n{layer.name}\"\n",
    "    return output_shape_txt, above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8185b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_model(model: Model, style: str = 'layered'):\n",
    "#     \"\"\"\n",
    "#     Generates and displays a visual architecture plot for a given Keras model.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Visualizing Architecture for: {model.name} (Style: {style}) ---\")\n",
    "    \n",
    "#     color_map = defaultdict(lambda: {'fill': '#999999'})\n",
    "#     color_map[Conv2D] = {'fill': '#00B8D4'}\n",
    "#     color_map[MaxPooling2D] = {'fill': '#FFAB00'}\n",
    "#     color_map[Dense] = {'fill': '#651FFF'}\n",
    "#     color_map[Flatten] = {'fill': '#E91E63'}\n",
    "#     color_map[Normalization] = {'fill': '#BDBDBD'}\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        \n",
    "#         if style == 'layered':\n",
    "#             # Generate the 3D-style block diagram using the text_callable function\n",
    "#             display(visualkeras.layered_view(\n",
    "#                 model,\n",
    "#                 text_callable=text_callable, \n",
    "#                 color_map=color_map,\n",
    "#                 scale_xy=12,\n",
    "#                 scale_z=1.2,\n",
    "#                 spacing=40\n",
    "#             ))\n",
    "#         elif style == 'graph':\n",
    "#             # Generate the 2D flowchart diagram.\n",
    "#             display(visualkeras.graph_view(\n",
    "#                 model,\n",
    "#                 color_map=color_map\n",
    "#             ))\n",
    "#         else:\n",
    "#             print(f\"Error: Unknown style '{style}'. Please choose 'layered' or 'graph'.\")\n",
    "\n",
    "\n",
    "\n",
    "def visualize_model(model: Model, style: str = 'layered'):\n",
    "    \"\"\"\n",
    "    Generates and displays a visual architecture plot for a given Keras model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Visualizing Architecture for: {model.name} (Style: {style}) ---\")\n",
    "    \n",
    "    color_map = defaultdict(lambda: {'fill': '#999999'})\n",
    "    color_map[Conv2D] = {'fill': '#00B8D4'}\n",
    "    color_map[MaxPooling2D] = {'fill': '#FFAB00'}\n",
    "    color_map[Dense] = {'fill': '#651FFF'}\n",
    "    color_map[Flatten] = {'fill': '#E91E63'}\n",
    "    color_map[Normalization] = {'fill': '#BDBDBD'}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        \n",
    "        if style == 'layered':\n",
    "            # --- CREATE A NEW MODEL WITH SPACING LAYERS FOR BETTER VISUALS ---\n",
    "            # This prevents the text labels from overlapping on the plot.\n",
    "            plot_model = Sequential()\n",
    "            for layer in model.layers:\n",
    "                plot_model.add(layer)\n",
    "                if 'conv' in layer.name or 'pool' in layer.name or 'dense' in layer.name:\n",
    "                     # Add a dummy layer after key layers for spacing\n",
    "                    plot_model.add(SpacingDummyLayer(spacing=30))\n",
    "            \n",
    "            display(visualkeras.layered_view(\n",
    "                plot_model, # Use the new model with spacing\n",
    "                text_callable=text_callable,\n",
    "                color_map=color_map,\n",
    "                scale_xy=10,\n",
    "                scale_z=1,\n",
    "                spacing=0, # Spacing is now handled by our dummy layers\n",
    "                padding=50 # Add padding to prevent text cutoff at the edges\n",
    "            ))\n",
    "        elif style == 'graph':\n",
    "            display(visualkeras.graph_view(\n",
    "                model,\n",
    "                color_map=color_map\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"Error: Unknown style '{style}'. Please choose 'layered' or 'graph'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de9b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Visualizing Architecture for: Base_CNN (Style: layered) ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer max_pooling2d_2 has never been called and thus has no defined output.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m model_instance = model_creation_function()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 2. Call the plotting function to visualize it\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# THE FIX IS HERE: We call our helper function, not the base library.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mvisualize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlayered\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# visualize_model(model_instance, style='graph')\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Add a separator for clarity\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mvisualize_model\u001b[39m\u001b[34m(model, style)\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mconv\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer.name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpool\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer.name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer.name:\n\u001b[32m     61\u001b[39m              \u001b[38;5;66;03m# Add a dummy layer after key layers for spacing\u001b[39;00m\n\u001b[32m     62\u001b[39m             plot_model.add(SpacingDummyLayer(spacing=\u001b[32m30\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     display(\u001b[43mvisualkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayered_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplot_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the new model with spacing\u001b[39;49;00m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_callable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscale_xy\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscale_z\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspacing\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Spacing is now handled by our dummy layers\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Add padding to prevent text cutoff at the edges\u001b[39;49;00m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m style == \u001b[33m'\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     74\u001b[39m     display(visualkeras.graph_view(\n\u001b[32m     75\u001b[39m         model,\n\u001b[32m     76\u001b[39m         color_map=color_map\n\u001b[32m     77\u001b[39m     ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timvo\\OneDrive\\Documents\\VSC Projects\\CSE5ML\\Assessment 2\\TF_NN_MNIST\\.venv\\Lib\\site-packages\\visualkeras\\layered.py:134\u001b[39m, in \u001b[36mlayered_view\u001b[39m\u001b[34m(model, to_file, min_z, min_xy, max_z, max_xy, scale_z, scale_xy, type_ignore, index_ignore, color_map, one_dim_orientation, index_2D, background_fill, draw_volume, draw_reversed, padding, text_callable, text_vspacing, spacing, draw_funnel, shade_step, legend, legend_text_spacing_offset, font, font_color, show_dimension)\u001b[39m\n\u001b[32m    132\u001b[39m     output_shape = layer.output_shape\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     output_shape = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m.shape\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_shape, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    137\u001b[39m     shape = output_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timvo\\OneDrive\\Documents\\VSC Projects\\CSE5ML\\Assessment 2\\TF_NN_MNIST\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:287\u001b[39m, in \u001b[36mOperation.output\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moutput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    279\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[32m    280\u001b[39m \n\u001b[32m    281\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m \u001b[33;03m        Output tensor or list of output tensors.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timvo\\OneDrive\\Documents\\VSC Projects\\CSE5ML\\Assessment 2\\TF_NN_MNIST\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:306\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    291\u001b[39m \n\u001b[32m    292\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    307\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m     )\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer max_pooling2d_2 has never been called and thus has no defined output."
     ]
    }
   ],
   "source": [
    "# Now, loop through, create each model \"on the fly\", and plot it\n",
    "for model_creation_function in cnn_model_functions:\n",
    "    # 1. Create the model instance from the function\n",
    "    model_instance = model_creation_function()\n",
    "    \n",
    "    # 2. Call the plotting function to visualize it\n",
    "    # THE FIX IS HERE: We call our helper function, not the base library.\n",
    "    visualize_model(model_instance, style='layered')\n",
    "    # visualize_model(model_instance, style='graph')\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\") # Add a separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6292216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameter Set for the Base CNN ---\n",
    "cnn_epochs = 100\n",
    "cnn_batch_size = 64\n",
    "cnn_exp_1_config = {\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "cnn_exp_2_config = {\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "\n",
    "cnn_exp_3_config = {\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "\n",
    "cnn_exp_4_config = {\n",
    "    \"optimiser\": \"SGD\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": cnn_epochs,\n",
    "    \"batch_size\": cnn_batch_size\n",
    "}\n",
    "\n",
    "cnn_config = [cnn_exp_2_config, cnn_exp_3_config, cnn_exp_4_config]\n",
    "# cnn_exp_1_config,  We do not need to include the cnn_exp_1_config, because we have already run this on all models. \n",
    "# In the cell below, setting the all_exp_params is a flag that ensure that when set to True, all models are trained on all parameters (computationally intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cnn_experiments = False # A simple flag to control whether we run the CNN experiments or not. This is convenient because CNN experiments take longer to run.\n",
    "# and when we restart the notebook, we might want to just run the MLP experiments first.\n",
    "all_exp_params = True\n",
    "\n",
    "# --- Run the full list of experiments ---\n",
    "if run_cnn_experiments:\n",
    "    cnn_histories = []\n",
    "    for cnn_model_function in cnn_model_functions:\n",
    "        if not all_exp_params:\n",
    "            cnn_history = run_experiment(\n",
    "                model_creation_func=cnn_model_function, \n",
    "                hyperparameters=cnn_exp_1_config,  # If we do not set the all experiment parameters to True, then we only need the 1 config file. \n",
    "                parent_folder='CNN_Models',\n",
    "                X_train=X_train,\n",
    "                Y_train=Y_train,\n",
    "            )\n",
    "        else:\n",
    "            for config in cnn_config:\n",
    "                cnn_history = run_experiment(\n",
    "                    model_creation_func=cnn_model_function, \n",
    "                    hyperparameters=config, \n",
    "                    parent_folder='CNN_Models',\n",
    "                    X_train=X_train,\n",
    "                    Y_train=Y_train,\n",
    "                )\n",
    "\n",
    "        cnn_histories.append(cnn_history)\n",
    "\n",
    "# # --- To run the second experiment, we just call it again with a different config (hyper parameter set) :-)\n",
    "# --- We first  test different model architectures before running more experiments with different hyperparameters (Part 1 Task 1 & 2). ---\n",
    "# --- THen we test the best performing model of Part 1 Task 1& 2 with different hyperparameters. ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c387c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Plotting Function ---\n",
    "\n",
    "def plot_training_history(history: History):\n",
    "    \"\"\"\n",
    "    Plots training history and automatically extracts hyperparameters \n",
    "    from the history object itself.\n",
    "    \"\"\"\n",
    "    # --- Extract the hyperparameters that we attached ---\n",
    "    # We can now access them directly from the history object!\n",
    "    config = history.hyperparameters\n",
    "    \n",
    "    optimizer_name = config.get('optimiser', 'N/A')\n",
    "    learning_rate = config.get('learning_rate', 'N/A')\n",
    "    batch_size = config.get('batch_size', 'N/A')\n",
    "\n",
    "    # --- Create the subtitle for the plots ---\n",
    "    subtitle = f\"Optimizer: {optimizer_name}, LR: {learning_rate}, Batch Size: {batch_size}\"\n",
    "\n",
    "    # --- Plotting Code (Same as before) ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.suptitle(f'{history.model.name}\\n{subtitle}') # Main title with subtitle\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for subtitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08790f",
   "metadata": {},
   "source": [
    "### Plot the results of every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple wrapper function to print all histories in a list.\n",
    "def print_training_histories(histories):\n",
    "    print(f\"The number of models to plot: {len(histories)}\")\n",
    "    for history in histories:\n",
    "        print(f\"Model number: {histories.index(history)+1}\")\n",
    "        plot_training_history(history)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "if run_mlp_experiments:\n",
    "    print_training_histories(mlp_histories)\n",
    "if run_cnn_experiments:\n",
    "    print_training_histories(cnn_histories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab5e2",
   "metadata": {},
   "source": [
    "## Testing the models on the held-out test set\n",
    "We test the model on the test data, which is data that the model has never seen before. Then we verify the model's real-world accuracy. It is expected that this does not deviate much from the validation sets, because the MNIST dataset contains images that are very clean and simple:\n",
    "- They are small (28 x 28 pixels only).\n",
    "- The digits are centered and normalised in size.\n",
    "- The background is a solid colour with no distracting noise.\n",
    "  \n",
    "Because of this simplicity, the patterns that differentiate one digit from another (e.g., a \"1\" is a vertical line, an \"8\" is two loops) are very strong and easy for our model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af8a5",
   "metadata": {},
   "source": [
    "First we define a function that browser to a folder with saved models, extracts the file with the highest validation accuracy in its name, loads it and tests it with the held-out X_test and Y_test. \n",
    "\n",
    "A function is convenient because we will use it on different models, with different hyperparameters and hence, avoid repetition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_load_and_analyse_best_model(\n",
    "    parent_folder: str, # Changed name for clarity\n",
    "    x_test_data: NDArray[np.float32], \n",
    "    y_test_data: NDArray[np.int_]\n",
    ") -> Tuple[tf.keras.Model | None, float | None, float | None]:\n",
    "    \"\"\"\n",
    "    Recursively searches through all subfolders in a parent directory to find the\n",
    "    single best Keras model, then loads and analyses it.\n",
    "    \"\"\"\n",
    "    best_model_path = None # We will now store the full path directly\n",
    "    best_val_accuracy = -1.0\n",
    "\n",
    "    pattern = re.compile(r\"val_acc-([\\d.]+)\\.keras\")\n",
    "\n",
    "    if not os.path.isdir(parent_folder):\n",
    "        print(f\"Error: Parent directory not found at '{parent_folder}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    # --- NEW: Use os.walk() to search through all subdirectories ---\n",
    "    # os.walk() goes through a directory tree top-down.\n",
    "    for dirpath, _, filenames in os.walk(parent_folder):\n",
    "        for filename in filenames:\n",
    "            match = pattern.search(filename)\n",
    "            if match:\n",
    "                val_accuracy = float(match.group(1))\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    # Construct and store the full path to this new best model\n",
    "                    best_model_path = os.path.join(dirpath, filename)\n",
    "    \n",
    "    # The rest of the function works perfectly, we just need to use best_model_path\n",
    "    if best_model_path:\n",
    "        print(f\"Found and loading best model across all experiments: {best_model_path}\")\n",
    "        \n",
    "        loaded_model = tf.keras.models.load_model(best_model_path)\n",
    "        \n",
    "        # --- Print Compiled Hyperparameters ---\n",
    "        print(\"\\n--- Key Hyperparameters ---\")\n",
    "        # Gets the configuration of the model's optimiser.\n",
    "        optimiser_config = loaded_model.optimizer.get_config()\n",
    "        optimiser_name = optimiser_config['name']\n",
    "        learning_rate = optimiser_config['learning_rate']\n",
    "        \n",
    "        # Gets the name of the loss function the model was compiled with.\n",
    "        loss_function = loaded_model.loss\n",
    "        \n",
    "        print(f\"{'Optimiser:':<20} {optimiser_name}\")\n",
    "        print(f\"{'Learning Rate:':<20} {learning_rate}\")\n",
    "        print(f\"{'Loss Function:':<20} {loss_function}\")\n",
    "        \n",
    "        # Prints a summary table of the model's architecture.\n",
    "        print(\"\\n--- Best Model Summary (Architecture) ---\")\n",
    "        loaded_model.summary()\n",
    "\n",
    "        # Evaluates the loaded model's performance on the unseen test data.\n",
    "        print(\"\\n--- Evaluating model performance on the test set ---\")\n",
    "        loss, accuracy = loaded_model.evaluate(x_test_data, y_test_data, verbose=1)\n",
    "        \n",
    "        # Prints the final evaluation results, formatted to 4 decimal places.\n",
    "        print(f\"\\nTest Set Loss: {loss:.4f}\")\n",
    "        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # --- Generate Detailed Performance Analysis ---\n",
    "        print(\"\\n--- Detailed Analysis ---\")\n",
    "        \n",
    "        # Use the model to predict the class for each image in the test set.\n",
    "        y_pred_probabilities = loaded_model.predict(x_test_data)\n",
    "        # The model outputs probabilities; we use np.argmax to find the class with the highest probability.\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "        # Generate and print a text report showing precision, recall, and f1-score for each digit.\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        report = classification_report(y_test_data, y_pred, target_names=[str(i) for i in range(10)])\n",
    "        print(report)\n",
    "\n",
    "        # Generate and plot a confusion matrix to visualise which digits are being confused.\n",
    "        print(\"\\n--- Confusion Matrix ---\")\n",
    "        cm = confusion_matrix(y_test_data, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('Actual Label')\n",
    "        plt.title(f'Confusion Matrix for {loaded_model.name}')\n",
    "        plt.show()\n",
    "        \n",
    "        # Returns the loaded model object and its performance metrics for potential further use.\n",
    "        return loaded_model, accuracy, loss\n",
    "    else:\n",
    "        # If no model files matching the pattern were found, print a message and return nothing.\n",
    "        print(f\"No model files found in any subfolders of '{parent_folder}'.\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24f712",
   "metadata": {},
   "source": [
    "### Testing the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder=\"MLP_Models\"\n",
    "# To capture the output, assign it to variables\n",
    "best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "    parent_folder=model_folder,\n",
    "    x_test_data=X_test,\n",
    "    y_test_data=Y_test\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2e325",
   "metadata": {},
   "source": [
    "### Testing the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_cnn_experiments:\n",
    "    model_folder='CNN_Models'\n",
    "    # To capture the output, assign it to variables\n",
    "    best_model, test_acc, test_loss = find_load_and_analyse_best_model(\n",
    "        parent_folder=model_folder,\n",
    "        x_test_data=X_test,\n",
    "        y_test_data=Y_test\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9820dc3",
   "metadata": {},
   "source": [
    "# Future to do's (not part of this assessment)\n",
    "- Implement KerasTuner, to automatically train and test models with a plethora of hyperparamaters, optimisers, loss functions:\n",
    "\n",
    "We first need to install it first: uv pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"This is our hypermodel, which defines the search space.\"\"\"\n",
    "    \n",
    "    model = Sequential(name=\"Tuned_MLP\")\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Normalization())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # --- Define Hyperparameters to Tune ---\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    # Tune the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Add the output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # --- Compile the model inside the function ---\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "--- Set up the Tuner ---\n",
    "### We'll use RandomSearch, which randomly tries combinations.\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # The total number of model variations to test\n",
    "    executions_per_trial=2, # The number of times to train each model variation\n",
    "    directory='tuning_results',\n",
    "    project_name='MNIST_Tuning'\n",
    ")\n",
    "\n",
    "### --- Start the Search ---\n",
    "### This is like model.fit(), but it runs the whole tuning process.\n",
    "tuner.search(X_train, Y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "### --- Get the Best Model ---\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\n--- Best Hyperparameters Found ---\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "print(\"\\n--- Evaluating the Best Model Found by the Tuner ---\")\n",
    "best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428276c",
   "metadata": {},
   "source": [
    "# Testing a new approach (Future to do)\n",
    "### A Base Class for models, with a common interface and allowing for inheriting layers, inheriting behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # models.py\n",
    "# # This file serves as a centralised factory for creating our neural network models.\n",
    "# # It uses a class-based, inherited structure to keep the codebase organised and extensible.\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Normalization, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# class BaseNeuralNetwork(Model):\n",
    "#     \"\"\"\n",
    "#     A base class for all neural networks in this project.\n",
    "#     It encapsulates the common input and preprocessing layers that all models will share.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, **kwargs):\n",
    "#         # We call the parent constructor to ensure correct initialisation of the Keras Model.\n",
    "#         # **kwargs allows us to pass additional arguments like 'name' when creating subclasses.\n",
    "#         super().__init__(**kwargs)\n",
    "#         # These layers are common to all models and are defined here once for efficiency.\n",
    "#         self.normalization_layer = Normalization(name=\"normalization_layer\")\n",
    "#         self.flatten_layer = Flatten(name=\"flatten_layer\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         \"\"\"\n",
    "#         Defines the forward pass for the common preprocessing layers.\n",
    "#         \"\"\"\n",
    "#         # The input data is passed through the normalisation and flattening layers.\n",
    "#         x = self.normalization_layer(inputs)\n",
    "#         x = self.flatten_layer(x)\n",
    "#         return x\n",
    "\n",
    "# class MLPModel(BaseNeuralNetwork):\n",
    "#     \"\"\"\n",
    "#     A standard Multi-Layer Perceptron (MLP) model.\n",
    "#     It inherits the base preprocessing from BaseNeuralNetwork and adds dense layers.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_units_1: int = 128, num_units_2: int = 256, num_units_3: int = 64, num_classes: int = 10, **kwargs):\n",
    "#         # We call the parent constructor and provide a specific name for this model.\n",
    "#         super().__init__(name='mlp_model', **kwargs)\n",
    "#         # Define the unique dense layers for this specific model architecture.\n",
    "#         self.dense_1 = Dense(units=num_units_1, activation='relu', name=\"dense_1\")\n",
    "#         self.dense_2 = Dense(units=num_units_2, activation='relu', name=\"dense_2\")\n",
    "#         self.dense_3 = Dense(units=num_units_3, activation='relu', name=\"dense_3\")\n",
    "#         self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # First, we process the input using the base class's call method.\n",
    "#         x = super().call(inputs)\n",
    "#         # Then, we pass the output through the MLP-specific layers.\n",
    "#         x = self.dense_1(x)\n",
    "#         x = self.dense_2(x)\n",
    "#         x = self.dense_3(x)\n",
    "#         return self.output_layer(x)\n",
    "\n",
    "# class MLP_Wide_Model(BaseNeuralNetwork):\n",
    "#     \"\"\"\n",
    "#     A wider, shallower MLP model. This is a variation for experimentation.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_units_1: int = 256, num_units_2: int = 128, num_classes: int = 10, **kwargs):\n",
    "#         super().__init__(name='mlp_wide_model', **kwargs)\n",
    "#         # This model has a different configuration of dense layers.\n",
    "#         self.dense_1 = Dense(units=num_units_1, activation='relu', name=\"dense_1\")\n",
    "#         self.dense_2 = Dense(units=num_units_2, activation='relu', name=\"dense_2\")\n",
    "#         self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = super().call(inputs)\n",
    "#         x = self.dense_1(x)\n",
    "#         x = self.dense_2(x)\n",
    "#         return self.output_layer(x)\n",
    "\n",
    "# class SimpleCNN(BaseNeuralNetwork):\n",
    "#     \"\"\"\n",
    "#     A simple Convolutional Neural Network (CNN) model for image classification.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_classes: int = 10, **kwargs):\n",
    "#         super().__init__(name='simple_cnn', **kwargs)\n",
    "#         # The convolutional and pooling layers are unique to CNNs.\n",
    "#         self.conv1 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', name=\"conv1\")\n",
    "#         self.pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool1\")\n",
    "#         self.conv2 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv2\")\n",
    "#         self.pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool2\")\n",
    "#         self.output_layer = Dense(units=num_classes, activation='softmax', name=\"output_layer\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # We start by using the base class's normalisation.\n",
    "#         x = self.normalization_layer(inputs)\n",
    "        \n",
    "#         # Then, we pass the output through the CNN-specific layers.\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool2(x)\n",
    "\n",
    "#         # The flatten layer from the base class is still applied before the output layer.\n",
    "#         x = self.flatten_layer(x)\n",
    "        \n",
    "#         return self.output_layer(x)\n",
    "\n",
    "# class DeepCNN(BaseNeuralNetwork):\n",
    "#     \"\"\"\n",
    "#     A deeper CNN model with more layers for greater representational capacity.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_classes: int = 10, **kwargs):\n",
    "#         super().__init__(name='deep_cnn', **kwargs)\n",
    "#         # This model has a more complex arrangement of convolutional layers.\n",
    "#         self.conv1 = Conv2D(32, (3, 3), activation='relu')\n",
    "#         self.conv2 = Conv2D(32, (3, 3), activation='relu')\n",
    "#         self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "#         self.conv3 = Conv2D(64, (3, 3), activation='relu')\n",
    "#         self.conv4 = Conv2D(64, (3, 3), activation='relu')\n",
    "#         self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "#         self.dense1 = Dense(128, activation='relu')\n",
    "#         self.output_layer = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = self.normalization_layer(inputs)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.flatten_layer(x)\n",
    "#         x = self.dense1(x)\n",
    "#         return self.output_layer(x)\n",
    "\n",
    "# def create_model_from_class(model_class: type, input_shape, **kwargs):\n",
    "#     \"\"\"\n",
    "#     A helper function to instantiate a model class with a defined input shape.\n",
    "#     It automatically builds the model for you.\n",
    "#     \"\"\"\n",
    "#     model_instance = model_class(**kwargs)\n",
    "#     # The build method ensures that the model's layers are initialised with the correct input shape.\n",
    "#     model_instance.build(input_shape=(None,) + input_shape)\n",
    "#     return model_instance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
